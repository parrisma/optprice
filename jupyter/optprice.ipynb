{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "02b97c38-59d0-4233-b2a0-4d76bf72a1c1",
   "metadata": {},
   "source": [
    "## Starting Point\n",
    "\n",
    "A pricing model we want to replicate with a neural network.\n",
    "\n",
    "## Motivation\n",
    "\n",
    "The belief that the neural network will cost less compute to train and predict prices (RFQs) faster than the full model. The use case will target complex path dependant (montecarlo) models that have a high compute cost and are relativly slow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c2ff9d9a-f095-49ba-a2a2-5cfd29a7801f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Some set-up for the NN environment, for this we are using TensorFlow and Keras.\n",
    "#\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import random\n",
    "import inspect\n",
    "import time\n",
    "import re\n",
    "from enum import Enum\n",
    "from typing import Tuple, List, Union, Callable\n",
    "from scipy.stats import norm\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from itertools import permutations\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "49948bc7-e4ae-4e6d-9883-7390b5c7bbd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# This is so we can visualise results\n",
    "#\n",
    "from mpl_toolkits.mplot3d import axes3d\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from matplotlib import cm\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ad119fc-9626-4870-a812-538e7815d32a",
   "metadata": {},
   "source": [
    "## Simple Model\n",
    "\n",
    "For the purpose of experimenting with the process we define a simple Black Scholes option model. This will allow us to show the work flow and highlight the challenges with the approach.\n",
    "\n",
    "The specific model implementation below is arbitrary, it is just a means to show how the neural network can learn a function of the same order of magnitude of complexity as a simple option contract."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "654fac00-de8a-4b9a-8189-23c099412250",
   "metadata": {},
   "outputs": [],
   "source": [
    "def black_scholes_model(S: float,\n",
    "                        K: float,\n",
    "                        T: float,\n",
    "                        r: float,\n",
    "                        v: float,\n",
    "                        o: float = float(0)) -> float:\n",
    "    \"\"\"\n",
    "    Implementation of Black Scholes model.\n",
    "\n",
    "    Trivial example to demo of proof of concept for fitting an option pricing model\n",
    "    with a neural network.\n",
    "\n",
    "    :param S: Spot\n",
    "    :param K: Strike\n",
    "    :param T: Time to maturity\n",
    "    :param r: risk free rate\n",
    "    :param v: underlying volatility\n",
    "    :param o: type, call = 0 or put = 1\n",
    "    :return: Option Price\n",
    "    \"\"\"\n",
    "    d1 = (np.log(S / K) + (r + 0.5 * v ** 2) * T) / (v * np.sqrt(T))\n",
    "    d2 = (np.log(S / K) + (r - 0.5 * v ** 2) * T) / (v * np.sqrt(T))\n",
    "\n",
    "    if o == 0.0:\n",
    "        return S * norm.cdf(d1) - K * np.exp(-r * T) * norm.cdf(d2)\n",
    "    if o == 1.0:\n",
    "        return K * np.exp(-r * T) * norm.cdf(-d2) - S * norm.cdf(-d1)\n",
    "\n",
    "    assert False, \"Option must be call=0 or put=1\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4796fa1a-4bff-4605-9cb2-79a2eab9771f",
   "metadata": {},
   "source": [
    "## Pricing Scenarios\n",
    "\n",
    "In the real use case we will collect the back history  RFQ ( (request for quote) as training data for the neural network. This presents the first challenge as to train the model we need a spread of data across all combinations of all parameters and instrument details that impact the price we are trying to predict. If we have gaps in our training data there will also be a weakness in the model when predicting prices with that specific combination of inputs.\n",
    "\n",
    "The nature of neural networks is to give results, even an totally untrained neural network will make predictions, just erroneous ones. So we will need to review the spread of inputs we have and make sure (expert judgment) that there are sufficient examples for all of teh combinations we are likely to quote. If the markets shift significantly we can also add additional training data, but we must be aware when the model is being asked to make predictions outside of its experience.\n",
    "\n",
    "In this example we will create training data from scratch by running scenarios by varying the input parameters and capturing the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64dbf09b-b6fd-4916-95d8-78e63eafb94f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parameter_scenarios(vol_range: Tuple[float, float] = (0.01, 0.4),\n",
    "                        mat_range: Tuple[float, float] = (1e-6, 1.0),\n",
    "                        spot_range: Tuple[float, float] = (1.0, 100.0),\n",
    "                        strike_range: Tuple[float, float] = (1.0, 100.0),\n",
    "                        rate_range: Tuple[float, float] = (0.01, 0.25),\n",
    "                        num_steps=50) -> Tuple[List[float], List[float], List[float], List[float], List[float]]:\n",
    "    \"\"\"\n",
    "    Create scenario vectors for volatility, maturity, spot, strike and risk-free rate\n",
    "\n",
    "    :param vol_range: The range to vary volatility over\n",
    "    :param mat_range: The range to vary maturity over\n",
    "    :param spot_range: The range to vary spot over\n",
    "    :param strike_range: The range to vary strike over\n",
    "    :param rate_range: The range to vary risk-free rate over\n",
    "    :param num_steps: number of scenario steps\n",
    "    :return: volatility, maturity, spot, strike and risk-free rate scenarios as list of float\n",
    "    \"\"\"\n",
    "    vols = [vol_range[0] + (x * ((vol_range[1] - vol_range[0]) / (num_steps - 1)))\n",
    "            for x in range(num_steps)]\n",
    "    mats = [mat_range[0] + (x * ((mat_range[1] - mat_range[0]) / (num_steps - 1)))\n",
    "            for x in range(num_steps)]\n",
    "    spots = [spot_range[0] + (x * ((spot_range[1] - spot_range[0]) / (num_steps - 1)))\n",
    "             for x in range(num_steps)]\n",
    "    strikes = [strike_range[0] + (x * ((strike_range[1] - strike_range[0]) /\n",
    "                                  (num_steps - 1))) for x in range(num_steps)]\n",
    "    rates = [rate_range[0] + (x * ((rate_range[1] - rate_range[0]) / (num_steps - 1)))\n",
    "             for x in range(num_steps)]\n",
    "    return vols, mats, spots, strikes, rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b027a3c-b41e-434f-b7f6-8d4f34579474",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combinations(list1: Union[List[float], float], list2: Union[List[float], float]) -> List:\n",
    "    \"\"\"\n",
    "    Return all combinations of the given lists\n",
    "\n",
    "    :param list1: The first list\n",
    "    :param list2: The second list\n",
    "    :return: List of all combinations of lists 1 and List 2\n",
    "    \"\"\"\n",
    "    if not isinstance(list1, List):\n",
    "        list1 = [list1]\n",
    "    if not isinstance(list2, List):\n",
    "        list2 = [list2]\n",
    "    res = []\n",
    "    for x in list1:\n",
    "        for y in list2:\n",
    "            if not isinstance(x, List):\n",
    "                x = [x]\n",
    "            if not isinstance(y, List):\n",
    "                y = [y]\n",
    "            res.append([*x, *y])\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a03dcad-0705-4a2d-ac88-50a24de68063",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_model_scenarios(spot: Union[List[float], float],\n",
    "                             strike: Union[List[float], float],\n",
    "                             mat: Union[List[float], float],\n",
    "                             rate: Union[List[float], float],\n",
    "                             vol: Union[List[float], float]\n",
    "                             ) -> List[Tuple[float, float, float, float, float]]:\n",
    "    \"\"\"\n",
    "    Return a set of model scenario inputs based on given parameter scenarios\n",
    "\n",
    "    :param vol: List of volatilities or single volatility\n",
    "    :param vol: List of maturities or single maturity\n",
    "    :param vol: List of spots or single spot\n",
    "    :param vol: List of strike or single strike\n",
    "    :param vol: List of rates or single rate\n",
    "    :return: List of all combinations [[s,k,t,r,v]]\n",
    "    \"\"\"\n",
    "    return combinations(combinations(combinations(combinations(spot, strike), mat), rate), vol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f0642a-065e-410a-aa8a-c8b7e5798b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def two_d_scenario(spot: Union[List[float], float],\n",
    "                   strike: Union[List[float], float],\n",
    "                   mat: Union[List[float], float],\n",
    "                   rate: Union[List[float], float],\n",
    "                   vol: Union[List[float], float],\n",
    "                   price_func: Callable,\n",
    "                   scaler=None) -> Tuple[List[float], str, List[float], str, np.ndarray]:\n",
    "\n",
    "    \"\"\"\n",
    "    Generate a scenario where two of the given parameters are scenarios\n",
    "\n",
    "    :param spot: spot scenario or single spot\n",
    "    :param strike: strike scenario or single strike\n",
    "    :param maturity: maturity scenario or single maturity\n",
    "    :param rate: rate scenario or single rate\n",
    "    :param vol: volatility scenario or single volatility\n",
    "    :param price_func: The pricing function, either black_scholes or model.predict\n",
    "    :param scaler: The scaler used to normalise the model inputs\n",
    "    :return: scenario List 1, scenario parameter 1 name, scenario List 2, scenario parameter 2 name, scenario prices\n",
    "\n",
    "    \"\"\"\n",
    "    params = [spot, strike, mat, rate, vol]\n",
    "    arg_names = [*inspect.signature(black_scholes_model).parameters.keys()]\n",
    "    scenario_params = [[x[0][0], x[0][1], x[1]] for x in zip(\n",
    "        enumerate(params), arg_names) if isinstance(x[0][1], List)]\n",
    "    assert (len(scenario_params) ==\n",
    "            2), \"Only two parameters can be passed as scenario lists\"\n",
    "    prices = np.zeros((len(scenario_params[0][1]), len(scenario_params[1][1])))\n",
    "    for i, x in enumerate(scenario_params[0][1]):\n",
    "        if scaler is None: # cell by cell\n",
    "            for j, y in enumerate(scenario_params[1][1]):\n",
    "                params[scenario_params[0][0]] = x\n",
    "                params[scenario_params[1][0]] = y\n",
    "                prices[i, j] = (price_func)(*params)\n",
    "        else: # row by row as it is quicker when calling model.predict\n",
    "            params[scenario_params[0][0]] = x\n",
    "            params[scenario_params[1][0]] = None\n",
    "            param_set = np.tile(np.asarray(params),\n",
    "                                (len(scenario_params[1][1]), 1))\n",
    "            param_set[:, scenario_params[1][0]] = scenario_params[1][1]\n",
    "            param_set = scaler.transform(param_set)\n",
    "            prices[i, :] = ((price_func)(param_set.astype(np.float64))).reshape(\n",
    "                1, len(scenario_params[1][1]))\n",
    "        print(\"{:0.0f} % Complete\".format(\n",
    "            100 * ((i*len(scenario_params[1][1]))/prices.size)))\n",
    "    print(\"Done\")\n",
    "    return scenario_params[0][1], scenario_params[0][2],  scenario_params[1][1], scenario_params[1][2], prices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89f0dc78-19f1-43ee-97e6-125de7d975fd",
   "metadata": {},
   "source": [
    "### Step 1. Generate parameter scenarios\n",
    "\n",
    "Generate a range for each model paramater type. These will be used to generate training data by calling the model for each combination of the parameters.\n",
    "\n",
    "In a real case we would try to collect this data as a side effect of where the real model was being used and only augment the training set where we observed gaps or thin spots in the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2108bc4d-3f43-4a6e-8245-e265ba978115",
   "metadata": {},
   "outputs": [],
   "source": [
    "vols, mats, spots, strikes, rates = parameter_scenarios(num_steps=20)\n",
    "X = generate_model_scenarios(spot=spots, strike=strikes, mat=mats, rate=rates, vol=vols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "483da04c-972f-48d8-abc0-f15a24406898",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = [black_scholes_model(*params) for params in X]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b63bb42-5061-4755-9cd3-dcfd5a8262da",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfy = pd.DataFrame(Y, columns=['price'])\n",
    "dfx = pd.DataFrame(X, columns=['vols', 'mats', 'spots', 'strikes', 'rates'])\n",
    "dfRaw = dfx.join(dfy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3694a1a2-5dec-43c2-8be2-c0250b901475",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfRaw.to_csv('XYRaw', encoding='ascii', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33ac744a-4203-4671-b43c-c3f9485660b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler(feature_range=(0, 1),copy=False).fit(X)\n",
    "XScaled = scaler.transform(X)\n",
    "dfxs = pd.DataFrame(XScaled, columns=['vols', 'mats', 'spots', 'strikes', 'rates'])\n",
    "dfScaled = dfxs.join(dfy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50294ea7-9ace-46d5-90e5-d6239e1dc7cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfScaled.to_csv('XYScaled', encoding='ascii', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bc92e2d-3b81-482d-b24c-6b5804856291",
   "metadata": {},
   "source": [
    "### Step 3. Create a neural network that can be regression trained to predict the price.\n",
    "\n",
    "This is where art meet science in that there are not hard and fast rules for the size, shape and architecture of a neural network that will be able to converge on a general form of teh function in a given set of data (if one exists). There are guidelines and many types of layer that fit certain patterns for image processing etc, so there is always informed experimentation at this stage.\n",
    "\n",
    "This is a very simple model as the data set is relatively small, however even a simple data set such as this took a number of experiments to get the right balance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b0f088b-5416-4d42-b54e-85e5d6554d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_neural_net():\n",
    "    \"\"\"\n",
    "    Create a Neural network with an architecture tuned to regression.\n",
    "    \"\"\"\n",
    "\n",
    "    # Create a NN of 5 Dense layers, with 5 inputs (number of BS parameters) abd a single\n",
    "    # output that predicts the price for the given parameters\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Dense(32, input_shape=(5,),\n",
    "                    kernel_initializer='normal', activation='tanh'))\n",
    "    model.add(Dense(16,\n",
    "                    kernel_initializer='normal', activation='tanh'))\n",
    "    model.add(Dense(8,\n",
    "                    kernel_initializer='normal', activation='tanh'))\n",
    "    model.add(Dense(4,\n",
    "                    kernel_initializer='normal', activation='tanh'))\n",
    "    model.add(Dense(2,\n",
    "                    kernel_initializer='normal', activation='tanh'))\n",
    "    model.add(Dense(1,\n",
    "                    kernel_initializer='normal', activation='linear'))\n",
    "\n",
    "    # Print the model architecture out\n",
    "    model.summary()\n",
    "\n",
    "    # Compile the model with the Adam optimizer, with a tuned step size.\n",
    "    opt = tf.keras.optimizers.Adam(learning_rate=0.0005)\n",
    "    model.compile(loss='mean_squared_error', optimizer=opt)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66cd3c9d-0c75-4d5e-846e-ea8002580379",
   "metadata": {},
   "source": [
    "### Step 5. Shuffle the training data & split into Test & Train data sets\n",
    "\n",
    "1. The training data is shuffled to improve training accuracy\n",
    "2. Split out a third of the data as a validation set\n",
    "3. Ensure all training and test data is pur numpy arrays (not always the case after using pipeline transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelType(Enum):\n",
    "    NEURAL_NET = 1\n",
    "    RANDOM_FOREST_REGRESSOR = 2\n",
    "\n",
    "\n",
    "def fit(X: np.ndarray,\n",
    "        Y: np.ndarray,\n",
    "        model_type: ModelType):\n",
    "    \"\"\"\n",
    "    Prepare the model inputs and fit the data with the given model type.\n",
    "    \n",
    "    :param X: Pricing parameter scenarios\n",
    "    :param Y: Prices corresponding to given inputs\n",
    "    :return : The tf model, training history & test and training data used X_train, Y_train, X_test, Y_test\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # Shuffle & scale the data\n",
    "\n",
    "    X = XScaled\n",
    "    Xs, Ys = shuffle(X, Y, random_state=42)\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(Xs, Ys, test_size=0.33)\n",
    "    X_train = np.asarray(X_train)\n",
    "    X_test = np.asarray(X_test)\n",
    "    Y_train = np.asarray(Y_train)\n",
    "    Y_test = np.asarray(Y_test)\n",
    "\n",
    "    # Create a check point to save the model version with the best validation loss\n",
    "\n",
    "    saveBest = ModelCheckpoint(filepath='best',\n",
    "                               monitor='val_loss',\n",
    "                               verbose=1,\n",
    "                               save_best_only=True,\n",
    "                               mode='min')\n",
    "\n",
    "    # Fit to the requested type\n",
    "\n",
    "    if model_type == ModelType.NEURAL_NET:\n",
    "        print(\"Create and fit Neural Network\")\n",
    "        model = create_neural_net()\n",
    "        history = model.fit(X_train, Y_train,\n",
    "                            batch_size=256,\n",
    "                            epochs=50,\n",
    "                            verbose=1,\n",
    "                            validation_data=(X_test, Y_test),\n",
    "                            callbacks=[saveBest])\n",
    "        model.load_weights('best') # load back the model corresponding to lowest validation loss\n",
    "    elif model_type == ModelType.RANDOM_FOREST_REGRESSOR:\n",
    "        print(\"Create and fit Random Forest Regressor\")\n",
    "        model = RandomForestRegressor(n_estimators=250, verbose=2)\n",
    "        model.fit(X_train, Y_train)\n",
    "        history = None\n",
    "    else:\n",
    "        assert False, \"Invalid model type specified, see model types defined by class ModelType\"\n",
    "\n",
    "    mse = mean_squared_error(model.predict(X_test), Y_test)\n",
    "    print(f\"Final Mean Square Error [{mse:5f}]\")\n",
    "    return model, history, X_train, Y_train, X_test, Y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f59f860-9c11-41e2-9b72-d145e60b1ced",
   "metadata": {},
   "source": [
    "### Step 6. Train the model but fitting to the given training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c522f7-ab68-4f65-9865-8f4a360df993",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, history,X_train, Y_train, X_test, Y_test = fit(X, Y, ModelType.NEURAL_NET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52244151-81a1-4120-9e5c-245f506fb727",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training_history(loss,\n",
    "                          validation_loss, \n",
    "                          skip=0):\n",
    "    \"\"\"\n",
    "    Plot a two axis line graph of training and validation losses\n",
    "    \n",
    "    :param loss: Training losses per epoch\n",
    "    :param validation_ loss: Validation losses per epoch\n",
    "    :param skip: don't plot the first skip points\n",
    "\n",
    "    \"\"\"\n",
    "    fig, ax1 = plt.subplots()\n",
    "    ax2 = ax1.twinx()\n",
    "    ax1.set_xlabel('Training Epoch')\n",
    "    ax1.set_ylabel('Loss', color='r')\n",
    "    ax2.set_ylabel('Validation Loss', color='b')\n",
    "    ax1.plot(loss[skip:], color='r')\n",
    "    ax2.plot(validation_loss[skip:], color='b')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3c54529-b01b-4dad-be97-04f98ca1059f",
   "metadata": {},
   "source": [
    "### Step 7. Examine the training losses and verify if model has learned a generalisation of the option function.\n",
    "\n",
    "We expect to see the Loss (red line) drop off exponentially as the model learns (fits) the data and the error between actual and predicted reduces.\n",
    "\n",
    "The validation loss (blue line) should also drop off as the model get better at predicting for test data (hold out) that it has not seen during training. If the loss increases, this is an indication that the model is too powerful and has just learned the training data (over fitted) rather than fitting a generalised form of the function in the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a93c873-91cb-4bae-a109-ad63d4cd4aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "if history is not None:\n",
    "    plot_training_history(history.history['loss'],\n",
    "                          history.history['val_loss'],\n",
    "                          skip=9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b722fdaf-e8a9-4c6c-accd-b55d3c14ea97",
   "metadata": {},
   "source": [
    "### Step 8. Generate a result set based on direct model calls.\n",
    "\n",
    "We generate a set of prices based on direct model calls so we can plot a pricing surface and see what the function looks like. This then also acts as the target surface we expect to see when we predict and plot the prices with the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vols, mats, spots, strikes, rates = parameter_scenarios(num_steps=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02986cd2-f0ed-4f95-abf4-fa159a0b0ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rate vs Vol Scenario\n",
    "s1,s1n,s2,s2n,actual = two_d_scenario(spot=99, strike=100, mat=0.75, rate=rates,vol=vols, price_func=black_scholes_model)\n",
    "s1,s1n,s2,s2n,predicted = two_d_scenario(spot=99, strike=100, mat=0.75, rate=rates,vol=vols, price_func=model.predict, scaler=scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1,s1n,s2,s2n,actual = two_d_scenario(spot=99, strike=100, mat=mats, rate=0.05,vol=vols, price_func=black_scholes_model)\n",
    "s1,s1n,s2,s2n,predicted = two_d_scenario(spot=99, strike=100, mat=mats, rate=0.05,vol=vols, price_func=model.predict, scaler=scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1,s1n,s2,s2n,actual = two_d_scenario(spot=spots, strike=strikes, mat=1.0, rate=0.05,vol=.2, price_func=black_scholes_model)\n",
    "s1,s1n,s2,s2n,predicted = two_d_scenario(spot=spots, strike=strikes, mat=1.0, rate=0.05,vol=0.2, price_func=model.predict, scaler=scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e99af539-763c-4d5f-851b-1202b04cc442",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_price_surface(xscen,\n",
    "                       yscen,\n",
    "                       actual,\n",
    "                       predicted,\n",
    "                       title,\n",
    "                       xscen_lab,\n",
    "                       yscen_lab):\n",
    "    \"\"\"\n",
    "    Plot dual surface of actual vs predicted, with a contour plot of price difference as %\n",
    "    \"\"\"\n",
    "    minz = min(np.min(actual), np.min(predicted))\n",
    "    maxz = max(np.max(actual), np.max(predicted))\n",
    "\n",
    "    X, Y = np.meshgrid(xscen, yscen)\n",
    "    fig = plt.figure(figsize=(10, 10))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    ax.set_zlim3d(minz, maxz)\n",
    "    c1 = ax.contourf(X, Y, ((actual-predicted)/np.maximum(1e-9,actual))*100.0,\n",
    "                     levels=range(-100, 100, 1), cmap=cm.RdGy, offset=np.min(minz))\n",
    "    s1 = ax.plot_surface(X, Y, actual, cmap=cm.coolwarm,\n",
    "                         linewidth=0, edgecolor='none', alpha=.7)\n",
    "    s2 = ax.plot_surface(X, Y, predicted, edgecolors='k',\n",
    "                         linewidth=0.1, color='gray', alpha=.3)\n",
    "    cax = fig.add_axes([ax.get_position().x1+0.05, ax.get_position().y0 +\n",
    "                       ((ax.get_position().height)*0.15), 0.02, (ax.get_position().height)*0.7])\n",
    "    cb = fig.colorbar(c1, cax=cax)\n",
    "    cb.ax.set_ylabel('% difference', rotation=270)\n",
    "    ax.set_xlabel(xscen_lab)\n",
    "    ax.set_ylabel(yscen_lab)\n",
    "    ax.set_zlabel(\"Option Price\")\n",
    "    ax.set_title(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53af8864-e988-46ae-8505-3e4e1c0cfd79",
   "metadata": {},
   "source": [
    "## Actual vs Predicted\n",
    "\n",
    "### Surface\n",
    "\n",
    "We plot the actuals as a surface (blue-red) and then overlay the predicted as a translucent gray surface, so we can see where the two diverge. We also plot a contour of the % difference at every point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc5d509-a3b5-4e5d-a3e1-36178bee4cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_price_surface(vols, mats, actual, predicted, title=\"Predicted vs Actual Comparison\",\n",
    "                   xscen_lab=s1n, yscen_lab=s2n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5063772-2abc-4b85-9391-3cfbe523680d",
   "metadata": {},
   "source": [
    "### Scatter \n",
    "If we scatter plot actual vs predicted then we would expect to see a straight line, as for any given scenario point the actual and predicted would be equal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf2396c-523b-45a4-9089-d4b7a80b9c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(actual.flatten(), predicted.flatten(), s=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function(jit_compile=True,\n",
    "             reduce_retracing=True,\n",
    "             input_signature=(tf.TensorSpec(shape=None, dtype=tf.float64),\n",
    "                              tf.TensorSpec(shape=None, dtype=tf.float64),\n",
    "                              tf.TensorSpec(shape=None, dtype=tf.float64),\n",
    "                              tf.TensorSpec(shape=None, dtype=tf.float64),\n",
    "                              tf.TensorSpec(shape=None, dtype=tf.float64),\n",
    "                              tf.TensorSpec(shape=None, dtype=tf.float64),\n",
    "                              tf.TensorSpec(shape=None, dtype=tf.float64),\n",
    "                              tf.TensorSpec(shape=None, dtype=tf.float64),))\n",
    "def binomial_model_tf(S: float,\n",
    "                      K: float,\n",
    "                      T: float,\n",
    "                      r: float,\n",
    "                      v: float,\n",
    "                      CallPut: float,\n",
    "                      EurAm: float,\n",
    "                      n: int = 1000) -> float:\n",
    "    '''\n",
    "    Binomial Tree for European and American calls and puts.\n",
    "\n",
    "    The break time up into steps param:n, and creates a corresponding binomial tree. The paths of the\n",
    "    tree are then traversed and the option price evaluated at each node. This then allows for a stock price\n",
    "    path dependent value to be obtained, which is then able to support the early exercise for American style\n",
    "    options.\n",
    "\n",
    "    This model is thus more compute intensive than the closed form equivalents. These path dependent models\n",
    "    are more typical for exotic (complex) options where there is no closed form solution. These are the type of\n",
    "    compute expensive options we would like to evaluate with a neural network, as we believe it is less expensive\n",
    "    to train the model and quicker to price, than it is to run large numbers of prices from the full path dependent\n",
    "    call.\n",
    "\n",
    "    :param S: Spot\n",
    "    :param K: Strike\n",
    "    :param T: Time to maturity\n",
    "    :param r: risk free rate\n",
    "    :param v: underlying volatility\n",
    "    :param callPut: Call = 0.0 or Put 1.0\n",
    "    :param EurAm: European = 0.0 or American 1.0\n",
    "    :return: Option Price\n",
    "    \"\"\"\n",
    "    '''\n",
    "    deltaT = tf.cast(T/n, dtype=tf.float64)\n",
    "    u = tf.cast(tf.exp(v*tf.sqrt(deltaT)), dtype=tf.float64)\n",
    "    d = tf.cast(1/u, dtype=tf.float64)\n",
    "    p = tf.cast((tf.exp(r*deltaT) - d)/(u - d), dtype=tf.float64)\n",
    "    q = tf.cast(1 - p, dtype=tf.float64)\n",
    "\n",
    "    nc = tf.cast(n, dtype=np.int32)\n",
    "    underlying = tf.zeros((nc+1, nc+1), dtype=tf.float64)\n",
    "    underlying = tf.tensor_scatter_nd_update(underlying, [[0, 0]], [S])\n",
    "\n",
    "    res = tf.scan(lambda a, x: a*u, elems=underlying[:, 0])\n",
    "    underlying = tf_updateColumn(underlying, 0, res)\n",
    "\n",
    "    return underlying\n",
    "\n",
    "    for i in range(1, nc+1):\n",
    "        underlying = tf.tensor_scatter_nd_update(\n",
    "            underlying, [[i, 0]], [underlying[i-1, 0]*u])\n",
    "        for j in range(1, i+1):\n",
    "            underlying = tf.tensor_scatter_nd_update(\n",
    "                underlying, [[i, j]], [underlying[i-1, j-1]*d])\n",
    "\n",
    "    return underlying\n",
    "\n",
    "    price = np.zeros((n+1, n+1))\n",
    "\n",
    "    for i in range(n+1):\n",
    "        if CallPut == float(0):\n",
    "            price[n, i] = max(0, underlying[n, i] - K)\n",
    "        elif CallPut == float(1):\n",
    "            price[n, i] = max(0, K - underlying[n, i])\n",
    "\n",
    "    for i in range(n-1, -1, -1):\n",
    "        for j in range(i+1):\n",
    "            if CallPut == float(0) and EurAm == float(0):\n",
    "                price[i, j] = max(\n",
    "                    0, underlying[i, j]-K, np.exp(-r*deltaT)*(p*price[i+1, j]+q*price[i+1, j+1]))\n",
    "            elif CallPut == float(1) and EurAm == float(0):\n",
    "                price[i, j] = max(\n",
    "                    0, K-underlying[i, j], np.exp(-r*deltaT)*(p*price[i+1, j]+q*price[i+1, j+1]))\n",
    "            elif CallPut == float(0) and EurAm == float(1):\n",
    "                price[i, j] = np.exp(-r*deltaT) * \\\n",
    "                    (p*price[i+1, j]+q*price[i+1, j+1])\n",
    "            elif CallPut == float(1) and EurAm == float(1):\n",
    "                price[i, j] = np.exp(-r*deltaT) * \\\n",
    "                    (p*price[i+1, j]+q*price[i+1, j+1])\n",
    "\n",
    "    return price[0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[  101.             0.             0.         ...     0.\n",
      "      0.             0.        ]\n",
      " [  101.64080435     0.             0.         ...     0.\n",
      "      0.             0.        ]\n",
      " [  102.28567435     0.             0.         ...     0.\n",
      "      0.             0.        ]\n",
      " ...\n",
      " [55660.53942914     0.             0.         ...     0.\n",
      "      0.             0.        ]\n",
      " [56013.68315128     0.             0.         ...     0.\n",
      "      0.             0.        ]\n",
      " [56369.06742821     0.             0.         ...     0.\n",
      "      0.             0.        ]], shape=(1001, 1001), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "print(binomial_model_tf(S=101, K=99, T=1, r=0.05, v=0.2, CallPut=0, EurAm=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[   3.142    6.284   12.568   25.136   50.272  100.544  201.088  402.176\n",
      "   804.352 1608.704]\n",
      " [   0.       0.       0.       0.       0.       0.       0.       0.\n",
      "     0.       0.   ]\n",
      " [   0.       0.       0.       0.       0.       0.       0.       0.\n",
      "     0.       0.   ]\n",
      " [   0.       0.       0.       0.       0.       0.       0.       0.\n",
      "     0.       0.   ]\n",
      " [   0.       0.       0.       0.       0.       0.       0.       0.\n",
      "     0.       0.   ]], shape=(5, 10), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "    S=tf.constant(3.142,dtype=tf.float64)\n",
    "    u=tf.constant(1.5,dtype=tf.float64)\n",
    "    d=tf.constant(2,dtype=tf.float64)\n",
    "    underlying = tf.zeros((5, 10), dtype=tf.float64)\n",
    "    underlying = tf.tensor_scatter_nd_update(underlying, [[0, 0]], [S])\n",
    "    res = tf.scan(lambda a, x: a*u, elems=underlying[:,0])\n",
    "    underlying = tf_updateColumn(underlying,0,res)\n",
    "    res = tf.scan(lambda a, x: a*d, elems=underlying[0,:])\n",
    "    underlying = tf_updateRow(underlying,0,res)\n",
    "    print(underlying)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_updateColumn(target, col_idx, col_vals):\n",
    "    rows = tf.stack(tf.range(tf.shape(target)[0]))\n",
    "    cols = tf.ones_like(rows)*col_idx\n",
    "    idx = tf.stack((rows, cols), axis=1)\n",
    "    res = tf.tensor_scatter_nd_update(target, idx, col_vals)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_updateRow(target, row_idx, row_vals):\n",
    "    rows = tf.stack(tf.range(tf.shape(target)[1]))\n",
    "    cols = tf.ones_like(rows)*row_idx\n",
    "    idx = tf.stack((cols, rows), axis=1)\n",
    "    res = tf.tensor_scatter_nd_update(target, idx, row_vals)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[0 0]\n",
      " [1 0]\n",
      " [2 0]\n",
      " [3 0]\n",
      " [4 0]\n",
      " [5 0]\n",
      " [6 0]\n",
      " [7 0]\n",
      " [8 0]\n",
      " [9 0]], shape=(10, 2), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "print(tf_updateRow(underlying,0,res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([2. 2. 2. 2. 2. 2.], shape=(6,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[1. 2. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 2. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 2. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 2. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 2. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 2. 1. 1. 1. 1. 1. 1. 1. 1.]], shape=(6, 10), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "x=tf.ones((6,10))\n",
    "v=tf.ones((6,))*2.0\n",
    "print(v)\n",
    "print(tf_updateColumn(x,1,v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function(input_signature=(tf.TensorSpec(shape=None, dtype=tf.float64),\n",
    "                              tf.TensorSpec(shape=None, dtype=tf.float64),\n",
    "                              tf.TensorSpec(shape=None, dtype=tf.float64),))\n",
    "def mx(a, b, c):\n",
    "    print(1)\n",
    "    underlying = tf.zeros((5, 5),dtype=tf.float64)\n",
    "    return tf.tensor_scatter_nd_update(underlying, [[0, 0]], [a*b*c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ab1de7-6f50-48b0-819e-2c3bab880e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function(jit_compile=True,\n",
    "             reduce_retracing=True,\n",
    "             input_signature=(tf.TensorSpec(shape=None, dtype=np.float64),\n",
    "                              tf.TensorSpec(shape=None, dtype=np.float64),\n",
    "                              tf.TensorSpec(shape=None, dtype=np.float64),\n",
    "                              tf.TensorSpec(shape=None, dtype=np.float64),\n",
    "                              tf.TensorSpec(shape=None, dtype=np.float64),\n",
    "                              tf.TensorSpec(shape=None, dtype=np.float64),\n",
    "                              tf.TensorSpec(shape=None, dtype=np.float64),\n",
    "                              tf.TensorSpec(shape=None, dtype=np.float64),))\n",
    "def binomial_model(S: float,\n",
    "                   K: float,\n",
    "                   T: float,\n",
    "                   r: float,\n",
    "                   v: float,\n",
    "                   CallPut: float,\n",
    "                   EurAm: float,\n",
    "                   n: int = 1000) -> float:\n",
    "    '''\n",
    "    Binomial Tree for European and American calls and puts.\n",
    "\n",
    "    The break time up into steps param:n, and creates a corresponding binomial tree. The paths of the\n",
    "    tree are then traversed and the option price evaluated at each node. This then allows for a stock price\n",
    "    path dependent value to be obtained, which is then able to support the early exercise for American style\n",
    "    options.\n",
    "\n",
    "    This model is thus more compute intensive than the closed form equivalents. These path dependent models\n",
    "    are more typical for exotic (complex) options where there is no closed form solution. These are the type of\n",
    "    compute expensive options we would like to evaluate with a neural network, as we believe it is less expensive\n",
    "    to train the model and quicker to price, than it is to run large numbers of prices from the full path dependent\n",
    "    call.\n",
    "\n",
    "    :param S: Spot\n",
    "    :param K: Strike\n",
    "    :param T: Time to maturity\n",
    "    :param r: risk free rate\n",
    "    :param v: underlying volatility\n",
    "    :param callPut: Call = 0.0 or Put 1.0\n",
    "    :param EurAm: European = 0.0 or American 1.0\n",
    "    :return: Option Price\n",
    "    \"\"\"\n",
    "    '''\n",
    "    deltaT = T/n\n",
    "    u = tf.exp(v*tf.sqrt(deltaT))\n",
    "    d = 1/u\n",
    "    p = (tf.exp(r*deltaT) - d)/(u - d)\n",
    "    q = 1 - p\n",
    "\n",
    "    underlying = np.zeros((n+1, n+1))\n",
    "    underlying[0, 0] = S\n",
    "    for i in range(1, n+1):\n",
    "        underlying[i, 0] = underlying[i-1, 0]*u\n",
    "        for j in range(1, i+1):\n",
    "            underlying[i, j] = underlying[i-1, j-1]*d\n",
    "\n",
    "    price = tf.zeros((n+1, n+1))\n",
    "\n",
    "    for i in range(n+1):\n",
    "        if CallPut == float(0):\n",
    "            price[n, i] = max(0, underlying[n, i] - K)\n",
    "        elif CallPut == float(1):\n",
    "            price[n, i] = max(0, K - underlying[n, i])\n",
    "\n",
    "    for i in range(n-1, -1, -1):\n",
    "        for j in range(i+1):\n",
    "            if CallPut == float(0) and EurAm == float(0):\n",
    "                price[i, j] = max(\n",
    "                    0, underlying[i, j]-K, tf.exp(-r*deltaT)*(p*price[i+1, j]+q*price[i+1, j+1]))\n",
    "            elif CallPut == float(1) and EurAm == float(0):\n",
    "                price[i, j] = max(\n",
    "                    0, K-underlying[i, j], tf.exp(-r*deltaT)*(p*price[i+1, j]+q*price[i+1, j+1]))\n",
    "            elif CallPut == float(0) and EurAm == float(1):\n",
    "                price[i, j] = tf.exp(-r*deltaT) * \\\n",
    "                    (p*price[i+1, j]+q*price[i+1, j+1])\n",
    "            elif CallPut == float(1) and EurAm == float(1):\n",
    "                price[i, j] = tf.exp(-r*deltaT) * \\\n",
    "                    (p*price[i+1, j]+q*price[i+1, j+1])\n",
    "\n",
    "    return price[0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_it(code: str) -> float:\n",
    "    \"\"\"\n",
    "    Run the given code and return time in seconds for it to run\n",
    "\n",
    "    :param code: The code to time\n",
    "    :return: runtime in seconds\n",
    "    \"\"\"\n",
    "    st = time.time()\n",
    "    eval(code)\n",
    "    return (time.time()-st)*10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "in user code:\n\n    File \"C:\\Users\\parri\\AppData\\Local\\Temp\\ipykernel_432\\362485379.py\", line 49, in binomial_model  *\n        underlying = np.zeros((n+1, n+1))\n\n    TypeError: 'Tensor' object cannot be interpreted as an integer\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32md:\\devroot\\optprice\\jupyter\\optprice.ipynb Cell 43\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/devroot/optprice/jupyter/optprice.ipynb#X55sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m Sv\u001b[39m=\u001b[39m\u001b[39m99\u001b[39m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/devroot/optprice/jupyter/optprice.ipynb#X55sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m binomial_model(S\u001b[39m=\u001b[39;49mSv, K\u001b[39m=\u001b[39;49m\u001b[39m99\u001b[39;49m, T\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m, r\u001b[39m=\u001b[39;49m\u001b[39m0.05\u001b[39;49m, v\u001b[39m=\u001b[39;49m\u001b[39m0.2\u001b[39;49m, CallPut\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m, EurAm\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/devroot/optprice/jupyter/optprice.ipynb#X55sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m#print(\"{:10.4f} Seconds\".format(time_it(\"black_scholes_model(S=100, K=99, T=1, r=0.05, v=0.2)\")))\u001b[39;00m\n",
      "File \u001b[1;32md:\\anaconda\\anaconda3\\envs\\tfgpu\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m--> 153\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    154\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m    155\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_file15bir7gl.py:39\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__binomial_model\u001b[1;34m(S, K, T, r, v, CallPut, EurAm, n)\u001b[0m\n\u001b[0;32m     37\u001b[0m p \u001b[39m=\u001b[39m (ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(tf)\u001b[39m.\u001b[39mexp, (ag__\u001b[39m.\u001b[39mld(r) \u001b[39m*\u001b[39m ag__\u001b[39m.\u001b[39mld(deltaT),), \u001b[39mNone\u001b[39;00m, fscope) \u001b[39m-\u001b[39m ag__\u001b[39m.\u001b[39mld(d)) \u001b[39m/\u001b[39m (ag__\u001b[39m.\u001b[39mld(u) \u001b[39m-\u001b[39m ag__\u001b[39m.\u001b[39mld(d))\n\u001b[0;32m     38\u001b[0m q \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m \u001b[39m-\u001b[39m ag__\u001b[39m.\u001b[39mld(p)\n\u001b[1;32m---> 39\u001b[0m underlying \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(np)\u001b[39m.\u001b[39mzeros, ((ag__\u001b[39m.\u001b[39mld(n) \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m, ag__\u001b[39m.\u001b[39mld(n) \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m),), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[0;32m     40\u001b[0m ag__\u001b[39m.\u001b[39mld(underlying)[\u001b[39m0\u001b[39m, \u001b[39m0\u001b[39m] \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mld(S)\n\u001b[0;32m     42\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_state_1\u001b[39m():\n",
      "\u001b[1;31mTypeError\u001b[0m: in user code:\n\n    File \"C:\\Users\\parri\\AppData\\Local\\Temp\\ipykernel_432\\362485379.py\", line 49, in binomial_model  *\n        underlying = np.zeros((n+1, n+1))\n\n    TypeError: 'Tensor' object cannot be interpreted as an integer\n"
     ]
    }
   ],
   "source": [
    "Sv=99\n",
    "binomial_model(S=Sv, K=99, T=1, r=0.05, v=0.2, CallPut=0, EurAm=0)\n",
    "#print(\"{:10.4f} Seconds\".format(time_it(\"black_scholes_model(S=100, K=99, T=1, r=0.05, v=0.2)\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(binomial_model.pretty_printed_concrete_signatures())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function(input_signature=(tf.TensorSpec(shape=None, dtype=tf.float64),\n",
    "                              tf.TensorSpec(shape=None, dtype=tf.float64),\n",
    "                              tf.TensorSpec(shape=None, dtype=tf.float64),))\n",
    "def mx(a, b, c):\n",
    "    underlying = tf.zeros((5, 5),dtype=tf.float64)\n",
    "    tf.tensor_scatter_nd_update(underlying, [[0, 0]], a*b*c)\n",
    "    return tf.tensor_scatter_nd_update(underlying, [[0, 0]], [a*b*c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mx(5,9,3))\n",
    "print(mx.pretty_printed_concrete_signatures())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StringFeature:\n",
    "    \"\"\"Encodes string features as numeric values so they can be passed as model inputs\n",
    "    \"\"\"\n",
    "    features = [[re.compile(\"^[C|c].*\"), float(0)],\n",
    "                [re.compile(\"^[P|p].*\"), float(1)],\n",
    "                [re.compile(\"^[A|a].*\"), float(1)],\n",
    "                [re.compile(\"^[E|e].*\"), float(0)]]\n",
    "\n",
    "    @classmethod\n",
    "    def encode(cls, feature_as_string: str) -> float:\n",
    "        \"\"\"Return the given feature as its numeric equivalent or asset if feature not known\n",
    "\n",
    "        :param feature_as_string: The string feature to encode\n",
    "        :return: The feature as it's numeric equivalent\n",
    "        \"\"\"\n",
    "        encoded_feature = None\n",
    "        for f in cls.features:\n",
    "            if f[0].search(feature_as_string) is not None:\n",
    "                encoded_feature = f[1]\n",
    "                break\n",
    "        assert encoded_feature is not None, \"Unknown feature [{}], cannot encode\".format(\n",
    "            feature_as_string)\n",
    "        return encoded_feature\n",
    "\n",
    "    @classmethod\n",
    "    def decode(cls, values: List[float], time_steps: int) -> Tuple[float, float, float, float, float, str, str]:\n",
    "        S, K, T, r, v, c, s = values\n",
    "        return [S, K, T, r, v, time_steps, ['Call', 'Put'][int(c)], ['European', 'American'][int(s)]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extend feature set\n",
    "\n",
    "We need to extend the feature set to cover the option style, Call or Put and early exercise or not, American or European\n",
    "\n",
    "These string features needed encoding as numerical values so they can be passed to the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate features without type and style.\n",
    "vols, mats, spots, strikes, rates = parameter_scenarios(num_steps=20)\n",
    "X = generate_model_scenarios(spot=spots, strike=strikes, mat=mats, rate=rates, vol=vols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create all combinations with option type\n",
    "# Call = 0, Put = 1\n",
    "X = combinations(X, [0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create all combinations with option style\n",
    "# American (early exercise) = 0, European = 1\n",
    "X = combinations(X, [0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle the training data\n",
    "Xs = shuffle(X, random_state=42)\n",
    "#scaler = MinMaxScaler(feature_range=(0, 1),copy=False).fit(Xs)\n",
    "#Xss = scaler.transform(Xs)\n",
    "dfxs = pd.DataFrame(Xs, columns=['spot', 'strike', 'maturity', 'rate', 'volatility','call_put','amer_eur'])\n",
    "dfxs.to_csv('XFull.csv', encoding='ascii', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binomial_model_wrapper(args: List) -> float:\n",
    "    S, K, T, r, v, c, s = args\n",
    "    print(binomial_model(S, K, T, r, v, c, s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = dfxs.head(50).values.tolist()\n",
    "Y_train = []\n",
    "p = multiprocessing.Pool(2)\n",
    "p.map(binomial_model_wrapper, X_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
