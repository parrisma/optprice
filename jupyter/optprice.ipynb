{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "02b97c38-59d0-4233-b2a0-4d76bf72a1c1",
   "metadata": {},
   "source": [
    "## Starting Point\n",
    "\n",
    "A pricing model we want to replicate with a neural network.\n",
    "\n",
    "## Motivation\n",
    "\n",
    "The belief that the neural network will cost less compute to train and predict prices (RFQs) faster than the full model. The use case will target complex path dependant (montecarlo) models that have a high compute cost and are relativly slow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c2ff9d9a-f095-49ba-a2a2-5cfd29a7801f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Some set-up for the NN environment, for this we are using TensorFlow and Keras.\n",
    "#\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import random\n",
    "import inspect\n",
    "import time\n",
    "import re\n",
    "from enum import Enum\n",
    "from typing import Tuple, List, Union, Callable\n",
    "from scipy.stats import norm\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from itertools import permutations\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "49948bc7-e4ae-4e6d-9883-7390b5c7bbd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# This is so we can visualise results\n",
    "#\n",
    "from mpl_toolkits.mplot3d import axes3d\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from matplotlib import cm\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ad119fc-9626-4870-a812-538e7815d32a",
   "metadata": {},
   "source": [
    "## Simple Model\n",
    "\n",
    "For the purpose of experimenting with the process we define a simple Black Scholes option model. This will allow us to show the work flow and highlight the challenges with the approach.\n",
    "\n",
    "The specific model implementation below is arbitrary, it is just a means to show how the neural network can learn a function of the same order of magnitude of complexity as a simple option contract."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "id": "654fac00-de8a-4b9a-8189-23c099412250",
   "metadata": {},
   "outputs": [],
   "source": [
    "def black_scholes_model(S: float,\n",
    "                        K: float,\n",
    "                        T: float,\n",
    "                        r: float,\n",
    "                        v: float,\n",
    "                        o: float = float(0)) -> float:\n",
    "    \"\"\"\n",
    "    Implementation of Black Scholes model.\n",
    "\n",
    "    Trivial example to demo of proof of concept for fitting an option pricing model\n",
    "    with a neural network.\n",
    "\n",
    "    :param S: Spot\n",
    "    :param K: Strike\n",
    "    :param T: Time to maturity\n",
    "    :param r: risk free rate\n",
    "    :param v: underlying volatility\n",
    "    :param o: type, call = 0 or put = 1\n",
    "    :return: Option Price\n",
    "    \"\"\"\n",
    "    d1 = (np.log(S / K) + (r + 0.5 * v ** 2) * T) / (v * np.sqrt(T))\n",
    "    d2 = (np.log(S / K) + (r - 0.5 * v ** 2) * T) / (v * np.sqrt(T))\n",
    "\n",
    "    if o == 0.0:\n",
    "        return S * norm.cdf(d1) - K * np.exp(-r * T) * norm.cdf(d2)\n",
    "    if o == 1.0:\n",
    "        return K * np.exp(-r * T) * norm.cdf(-d2) - S * norm.cdf(-d1)\n",
    "\n",
    "    assert False, \"Option must be call=0 or put=1\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4796fa1a-4bff-4605-9cb2-79a2eab9771f",
   "metadata": {},
   "source": [
    "## Pricing Scenarios\n",
    "\n",
    "In the real use case we will collect the back history  RFQ ( (request for quote) as training data for the neural network. This presents the first challenge as to train the model we need a spread of data across all combinations of all parameters and instrument details that impact the price we are trying to predict. If we have gaps in our training data there will also be a weakness in the model when predicting prices with that specific combination of inputs.\n",
    "\n",
    "The nature of neural networks is to give results, even an totally untrained neural network will make predictions, just erroneous ones. So we will need to review the spread of inputs we have and make sure (expert judgment) that there are sufficient examples for all of teh combinations we are likely to quote. If the markets shift significantly we can also add additional training data, but we must be aware when the model is being asked to make predictions outside of its experience.\n",
    "\n",
    "In this example we will create training data from scratch by running scenarios by varying the input parameters and capturing the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "id": "64dbf09b-b6fd-4916-95d8-78e63eafb94f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parameter_scenarios(vol_range: Tuple[float, float] = (0.01, 0.4),\n",
    "                        mat_range: Tuple[float, float] = (1e-6, 1.0),\n",
    "                        spot_range: Tuple[float, float] = (1.0, 100.0),\n",
    "                        strike_range: Tuple[float, float] = (1.0, 100.0),\n",
    "                        rate_range: Tuple[float, float] = (0.01, 0.25),\n",
    "                        num_steps=50) -> Tuple[List[float], List[float], List[float], List[float], List[float]]:\n",
    "    \"\"\"\n",
    "    Create scenario vectors for volatility, maturity, spot, strike and risk-free rate\n",
    "\n",
    "    :param vol_range: The range to vary volatility over\n",
    "    :param mat_range: The range to vary maturity over\n",
    "    :param spot_range: The range to vary spot over\n",
    "    :param strike_range: The range to vary strike over\n",
    "    :param rate_range: The range to vary risk-free rate over\n",
    "    :param num_steps: number of scenario steps\n",
    "    :return: volatility, maturity, spot, strike and risk-free rate scenarios as list of float\n",
    "    \"\"\"\n",
    "    vols = [vol_range[0] + (x * ((vol_range[1] - vol_range[0]) / (num_steps - 1)))\n",
    "            for x in range(num_steps)]\n",
    "    mats = [mat_range[0] + (x * ((mat_range[1] - mat_range[0]) / (num_steps - 1)))\n",
    "            for x in range(num_steps)]\n",
    "    spots = [spot_range[0] + (x * ((spot_range[1] - spot_range[0]) / (num_steps - 1)))\n",
    "             for x in range(num_steps)]\n",
    "    strikes = [strike_range[0] + (x * ((strike_range[1] - strike_range[0]) /\n",
    "                                  (num_steps - 1))) for x in range(num_steps)]\n",
    "    rates = [rate_range[0] + (x * ((rate_range[1] - rate_range[0]) / (num_steps - 1)))\n",
    "             for x in range(num_steps)]\n",
    "    return vols, mats, spots, strikes, rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "id": "5b027a3c-b41e-434f-b7f6-8d4f34579474",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combinations(list1: Union[List[float], float], list2: Union[List[float], float]) -> List:\n",
    "    \"\"\"\n",
    "    Return all combinations of the given lists\n",
    "\n",
    "    :param list1: The first list\n",
    "    :param list2: The second list\n",
    "    :return: List of all combinations of lists 1 and List 2\n",
    "    \"\"\"\n",
    "    if not isinstance(list1, List):\n",
    "        list1 = [list1]\n",
    "    if not isinstance(list2, List):\n",
    "        list2 = [list2]\n",
    "    res = []\n",
    "    for x in list1:\n",
    "        for y in list2:\n",
    "            if not isinstance(x, List):\n",
    "                x = [x]\n",
    "            if not isinstance(y, List):\n",
    "                y = [y]\n",
    "            res.append([*x, *y])\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "id": "3a03dcad-0705-4a2d-ac88-50a24de68063",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_model_scenarios(spot: Union[List[float], float],\n",
    "                             strike: Union[List[float], float],\n",
    "                             mat: Union[List[float], float],\n",
    "                             rate: Union[List[float], float],\n",
    "                             vol: Union[List[float], float]\n",
    "                             ) -> List[Tuple[float, float, float, float, float]]:\n",
    "    \"\"\"\n",
    "    Return a set of model scenario inputs based on given parameter scenarios\n",
    "\n",
    "    :param vol: List of volatilities or single volatility\n",
    "    :param vol: List of maturities or single maturity\n",
    "    :param vol: List of spots or single spot\n",
    "    :param vol: List of strike or single strike\n",
    "    :param vol: List of rates or single rate\n",
    "    :return: List of all combinations [[s,k,t,r,v]]\n",
    "    \"\"\"\n",
    "    return combinations(combinations(combinations(combinations(spot, strike), mat), rate), vol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "id": "79f0642a-065e-410a-aa8a-c8b7e5798b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def two_d_scenario(spot: Union[List[float], float],\n",
    "                   strike: Union[List[float], float],\n",
    "                   mat: Union[List[float], float],\n",
    "                   rate: Union[List[float], float],\n",
    "                   vol: Union[List[float], float],\n",
    "                   price_func: Callable,\n",
    "                   scaler=None) -> Tuple[List[float], str, List[float], str, np.ndarray]:\n",
    "\n",
    "    \"\"\"\n",
    "    Generate a scenario where two of the given parameters are scenarios\n",
    "\n",
    "    :param spot: spot scenario or single spot\n",
    "    :param strike: strike scenario or single strike\n",
    "    :param maturity: maturity scenario or single maturity\n",
    "    :param rate: rate scenario or single rate\n",
    "    :param vol: volatility scenario or single volatility\n",
    "    :param price_func: The pricing function, either black_scholes or model.predict\n",
    "    :param scaler: The scaler used to normalise the model inputs\n",
    "    :return: scenario List 1, scenario parameter 1 name, scenario List 2, scenario parameter 2 name, scenario prices\n",
    "\n",
    "    \"\"\"\n",
    "    params = [spot, strike, mat, rate, vol]\n",
    "    arg_names = [*inspect.signature(black_scholes_model).parameters.keys()]\n",
    "    scenario_params = [[x[0][0], x[0][1], x[1]] for x in zip(\n",
    "        enumerate(params), arg_names) if isinstance(x[0][1], List)]\n",
    "    assert (len(scenario_params) ==\n",
    "            2), \"Only two parameters can be passed as scenario lists\"\n",
    "    prices = np.zeros((len(scenario_params[0][1]), len(scenario_params[1][1])))\n",
    "    for i, x in enumerate(scenario_params[0][1]):\n",
    "        if scaler is None: # cell by cell\n",
    "            for j, y in enumerate(scenario_params[1][1]):\n",
    "                params[scenario_params[0][0]] = x\n",
    "                params[scenario_params[1][0]] = y\n",
    "                prices[i, j] = (price_func)(*params)\n",
    "        else: # row by row as it is quicker when calling model.predict\n",
    "            params[scenario_params[0][0]] = x\n",
    "            params[scenario_params[1][0]] = None\n",
    "            param_set = np.tile(np.asarray(params),\n",
    "                                (len(scenario_params[1][1]), 1))\n",
    "            param_set[:, scenario_params[1][0]] = scenario_params[1][1]\n",
    "            param_set = scaler.transform(param_set)\n",
    "            prices[i, :] = ((price_func)(param_set.astype(np.float64))).reshape(\n",
    "                1, len(scenario_params[1][1]))\n",
    "        print(\"{:0.0f} % Complete\".format(\n",
    "            100 * ((i*len(scenario_params[1][1]))/prices.size)))\n",
    "    print(\"Done\")\n",
    "    return scenario_params[0][1], scenario_params[0][2],  scenario_params[1][1], scenario_params[1][2], prices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89f0dc78-19f1-43ee-97e6-125de7d975fd",
   "metadata": {},
   "source": [
    "### Step 1. Generate parameter scenarios\n",
    "\n",
    "Generate a range for each model paramater type. These will be used to generate training data by calling the model for each combination of the parameters.\n",
    "\n",
    "In a real case we would try to collect this data as a side effect of where the real model was being used and only augment the training set where we observed gaps or thin spots in the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2108bc4d-3f43-4a6e-8245-e265ba978115",
   "metadata": {},
   "outputs": [],
   "source": [
    "vols, mats, spots, strikes, rates = parameter_scenarios(num_steps=20)\n",
    "X = generate_model_scenarios(spot=spots, strike=strikes, mat=mats, rate=rates, vol=vols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "483da04c-972f-48d8-abc0-f15a24406898",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = [black_scholes_model(*params) for params in X]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b63bb42-5061-4755-9cd3-dcfd5a8262da",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfy = pd.DataFrame(Y, columns=['price'])\n",
    "dfx = pd.DataFrame(X, columns=['vols', 'mats', 'spots', 'strikes', 'rates'])\n",
    "dfRaw = dfx.join(dfy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3694a1a2-5dec-43c2-8be2-c0250b901475",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfRaw.to_csv('XYRaw', encoding='ascii', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33ac744a-4203-4671-b43c-c3f9485660b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler(feature_range=(0, 1),copy=False).fit(X)\n",
    "XScaled = scaler.transform(X)\n",
    "dfxs = pd.DataFrame(XScaled, columns=['vols', 'mats', 'spots', 'strikes', 'rates'])\n",
    "dfScaled = dfxs.join(dfy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50294ea7-9ace-46d5-90e5-d6239e1dc7cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfScaled.to_csv('XYScaled', encoding='ascii', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bc92e2d-3b81-482d-b24c-6b5804856291",
   "metadata": {},
   "source": [
    "### Step 3. Create a neural network that can be regression trained to predict the price.\n",
    "\n",
    "This is where art meet science in that there are not hard and fast rules for the size, shape and architecture of a neural network that will be able to converge on a general form of teh function in a given set of data (if one exists). There are guidelines and many types of layer that fit certain patterns for image processing etc, so there is always informed experimentation at this stage.\n",
    "\n",
    "This is a very simple model as the data set is relatively small, however even a simple data set such as this took a number of experiments to get the right balance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b0f088b-5416-4d42-b54e-85e5d6554d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_neural_net():\n",
    "    \"\"\"\n",
    "    Create a Neural network with an architecture tuned to regression.\n",
    "    \"\"\"\n",
    "\n",
    "    # Create a NN of 5 Dense layers, with 5 inputs (number of BS parameters) abd a single\n",
    "    # output that predicts the price for the given parameters\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Dense(32, input_shape=(5,),\n",
    "                    kernel_initializer='normal', activation='tanh'))\n",
    "    model.add(Dense(16,\n",
    "                    kernel_initializer='normal', activation='tanh'))\n",
    "    model.add(Dense(8,\n",
    "                    kernel_initializer='normal', activation='tanh'))\n",
    "    model.add(Dense(4,\n",
    "                    kernel_initializer='normal', activation='tanh'))\n",
    "    model.add(Dense(2,\n",
    "                    kernel_initializer='normal', activation='tanh'))\n",
    "    model.add(Dense(1,\n",
    "                    kernel_initializer='normal', activation='linear'))\n",
    "\n",
    "    # Print the model architecture out\n",
    "    model.summary()\n",
    "\n",
    "    # Compile the model with the Adam optimizer, with a tuned step size.\n",
    "    opt = tf.keras.optimizers.Adam(learning_rate=0.0005)\n",
    "    model.compile(loss='mean_squared_error', optimizer=opt)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66cd3c9d-0c75-4d5e-846e-ea8002580379",
   "metadata": {},
   "source": [
    "### Step 5. Shuffle the training data & split into Test & Train data sets\n",
    "\n",
    "1. The training data is shuffled to improve training accuracy\n",
    "2. Split out a third of the data as a validation set\n",
    "3. Ensure all training and test data is pur numpy arrays (not always the case after using pipeline transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelType(Enum):\n",
    "    NEURAL_NET = 1\n",
    "    RANDOM_FOREST_REGRESSOR = 2\n",
    "\n",
    "\n",
    "def fit(X: np.ndarray,\n",
    "        Y: np.ndarray,\n",
    "        model_type: ModelType):\n",
    "    \"\"\"\n",
    "    Prepare the model inputs and fit the data with the given model type.\n",
    "    \n",
    "    :param X: Pricing parameter scenarios\n",
    "    :param Y: Prices corresponding to given inputs\n",
    "    :return : The tf model, training history & test and training data used X_train, Y_train, X_test, Y_test\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # Shuffle & scale the data\n",
    "\n",
    "    X = XScaled\n",
    "    Xs, Ys = shuffle(X, Y, random_state=42)\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(Xs, Ys, test_size=0.33)\n",
    "    X_train = np.asarray(X_train)\n",
    "    X_test = np.asarray(X_test)\n",
    "    Y_train = np.asarray(Y_train)\n",
    "    Y_test = np.asarray(Y_test)\n",
    "\n",
    "    # Create a check point to save the model version with the best validation loss\n",
    "\n",
    "    saveBest = ModelCheckpoint(filepath='best',\n",
    "                               monitor='val_loss',\n",
    "                               verbose=1,\n",
    "                               save_best_only=True,\n",
    "                               mode='min')\n",
    "\n",
    "    # Fit to the requested type\n",
    "\n",
    "    if model_type == ModelType.NEURAL_NET:\n",
    "        print(\"Create and fit Neural Network\")\n",
    "        model = create_neural_net()\n",
    "        history = model.fit(X_train, Y_train,\n",
    "                            batch_size=256,\n",
    "                            epochs=50,\n",
    "                            verbose=1,\n",
    "                            validation_data=(X_test, Y_test),\n",
    "                            callbacks=[saveBest])\n",
    "        model.load_weights('best') # load back the model corresponding to lowest validation loss\n",
    "    elif model_type == ModelType.RANDOM_FOREST_REGRESSOR:\n",
    "        print(\"Create and fit Random Forest Regressor\")\n",
    "        model = RandomForestRegressor(n_estimators=250, verbose=2)\n",
    "        model.fit(X_train, Y_train)\n",
    "        history = None\n",
    "    else:\n",
    "        assert False, \"Invalid model type specified, see model types defined by class ModelType\"\n",
    "\n",
    "    mse = mean_squared_error(model.predict(X_test), Y_test)\n",
    "    print(f\"Final Mean Square Error [{mse:5f}]\")\n",
    "    return model, history, X_train, Y_train, X_test, Y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f59f860-9c11-41e2-9b72-d145e60b1ced",
   "metadata": {},
   "source": [
    "### Step 6. Train the model but fitting to the given training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c522f7-ab68-4f65-9865-8f4a360df993",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, history,X_train, Y_train, X_test, Y_test = fit(X, Y, ModelType.NEURAL_NET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52244151-81a1-4120-9e5c-245f506fb727",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training_history(loss,\n",
    "                          validation_loss, \n",
    "                          skip=0):\n",
    "    \"\"\"\n",
    "    Plot a two axis line graph of training and validation losses\n",
    "    \n",
    "    :param loss: Training losses per epoch\n",
    "    :param validation_ loss: Validation losses per epoch\n",
    "    :param skip: don't plot the first skip points\n",
    "\n",
    "    \"\"\"\n",
    "    fig, ax1 = plt.subplots()\n",
    "    ax2 = ax1.twinx()\n",
    "    ax1.set_xlabel('Training Epoch')\n",
    "    ax1.set_ylabel('Loss', color='r')\n",
    "    ax2.set_ylabel('Validation Loss', color='b')\n",
    "    ax1.plot(loss[skip:], color='r')\n",
    "    ax2.plot(validation_loss[skip:], color='b')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3c54529-b01b-4dad-be97-04f98ca1059f",
   "metadata": {},
   "source": [
    "### Step 7. Examine the training losses and verify if model has learned a generalisation of the option function.\n",
    "\n",
    "We expect to see the Loss (red line) drop off exponentially as the model learns (fits) the data and the error between actual and predicted reduces.\n",
    "\n",
    "The validation loss (blue line) should also drop off as the model get better at predicting for test data (hold out) that it has not seen during training. If the loss increases, this is an indication that the model is too powerful and has just learned the training data (over fitted) rather than fitting a generalised form of the function in the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a93c873-91cb-4bae-a109-ad63d4cd4aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "if history is not None:\n",
    "    plot_training_history(history.history['loss'],\n",
    "                          history.history['val_loss'],\n",
    "                          skip=9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b722fdaf-e8a9-4c6c-accd-b55d3c14ea97",
   "metadata": {},
   "source": [
    "### Step 8. Generate a result set based on direct model calls.\n",
    "\n",
    "We generate a set of prices based on direct model calls so we can plot a pricing surface and see what the function looks like. This then also acts as the target surface we expect to see when we predict and plot the prices with the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vols, mats, spots, strikes, rates = parameter_scenarios(num_steps=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02986cd2-f0ed-4f95-abf4-fa159a0b0ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rate vs Vol Scenario\n",
    "s1,s1n,s2,s2n,actual = two_d_scenario(spot=99, strike=100, mat=0.75, rate=rates,vol=vols, price_func=black_scholes_model)\n",
    "s1,s1n,s2,s2n,predicted = two_d_scenario(spot=99, strike=100, mat=0.75, rate=rates,vol=vols, price_func=model.predict, scaler=scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1,s1n,s2,s2n,actual = two_d_scenario(spot=99, strike=100, mat=mats, rate=0.05,vol=vols, price_func=black_scholes_model)\n",
    "s1,s1n,s2,s2n,predicted = two_d_scenario(spot=99, strike=100, mat=mats, rate=0.05,vol=vols, price_func=model.predict, scaler=scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1,s1n,s2,s2n,actual = two_d_scenario(spot=spots, strike=strikes, mat=1.0, rate=0.05,vol=.2, price_func=black_scholes_model)\n",
    "s1,s1n,s2,s2n,predicted = two_d_scenario(spot=spots, strike=strikes, mat=1.0, rate=0.05,vol=0.2, price_func=model.predict, scaler=scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e99af539-763c-4d5f-851b-1202b04cc442",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_price_surface(xscen,\n",
    "                       yscen,\n",
    "                       actual,\n",
    "                       predicted,\n",
    "                       title,\n",
    "                       xscen_lab,\n",
    "                       yscen_lab):\n",
    "    \"\"\"\n",
    "    Plot dual surface of actual vs predicted, with a contour plot of price difference as %\n",
    "    \"\"\"\n",
    "    minz = min(np.min(actual), np.min(predicted))\n",
    "    maxz = max(np.max(actual), np.max(predicted))\n",
    "\n",
    "    X, Y = np.meshgrid(xscen, yscen)\n",
    "    fig = plt.figure(figsize=(10, 10))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    ax.set_zlim3d(minz, maxz)\n",
    "    c1 = ax.contourf(X, Y, ((actual-predicted)/np.maximum(1e-9,actual))*100.0,\n",
    "                     levels=range(-100, 100, 1), cmap=cm.RdGy, offset=np.min(minz))\n",
    "    s1 = ax.plot_surface(X, Y, actual, cmap=cm.coolwarm,\n",
    "                         linewidth=0, edgecolor='none', alpha=.7)\n",
    "    s2 = ax.plot_surface(X, Y, predicted, edgecolors='k',\n",
    "                         linewidth=0.1, color='gray', alpha=.3)\n",
    "    cax = fig.add_axes([ax.get_position().x1+0.05, ax.get_position().y0 +\n",
    "                       ((ax.get_position().height)*0.15), 0.02, (ax.get_position().height)*0.7])\n",
    "    cb = fig.colorbar(c1, cax=cax)\n",
    "    cb.ax.set_ylabel('% difference', rotation=270)\n",
    "    ax.set_xlabel(xscen_lab)\n",
    "    ax.set_ylabel(yscen_lab)\n",
    "    ax.set_zlabel(\"Option Price\")\n",
    "    ax.set_title(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53af8864-e988-46ae-8505-3e4e1c0cfd79",
   "metadata": {},
   "source": [
    "## Actual vs Predicted\n",
    "\n",
    "### Surface\n",
    "\n",
    "We plot the actuals as a surface (blue-red) and then overlay the predicted as a translucent gray surface, so we can see where the two diverge. We also plot a contour of the % difference at every point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc5d509-a3b5-4e5d-a3e1-36178bee4cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_price_surface(vols, mats, actual, predicted, title=\"Predicted vs Actual Comparison\",\n",
    "                   xscen_lab=s1n, yscen_lab=s2n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5063772-2abc-4b85-9391-3cfbe523680d",
   "metadata": {},
   "source": [
    "### Scatter \n",
    "If we scatter plot actual vs predicted then we would expect to see a straight line, as for any given scenario point the actual and predicted would be equal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf2396c-523b-45a4-9089-d4b7a80b9c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(actual.flatten(), predicted.flatten(), s=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# https://github.com/google/tf-quant-finance/blob/master/tf_quant_finance/black_scholes/crr_binomial_tree_test.py\n",
    "#\n",
    "\n",
    "def _get_payoff_fn(strikes, is_call_options):\n",
    "    \"\"\"Constructs the payoff functions.\"\"\"\n",
    "    option_signs = tf.cast(is_call_options, dtype=strikes.dtype) * 2 - 1\n",
    "\n",
    "    def payoff(spots):\n",
    "        \"\"\"Computes payff for the specified options given the spot grid.\n",
    "\n",
    "        Args:\n",
    "          spots: Tensor of shape [batch_size, grid_size, 1]. The spot values at some\n",
    "            time.\n",
    "\n",
    "        Returns:\n",
    "          Payoffs for exercise at the specified strikes.\n",
    "        \"\"\"\n",
    "        return tf.nn.relu((spots - strikes) * option_signs)\n",
    "\n",
    "    return payoff\n",
    "\n",
    "\n",
    "def _get_value_modifier(is_american, payoff_fn):\n",
    "    \"\"\"Constructs the value modifier for american style exercise.\"\"\"\n",
    "\n",
    "    def modifier(values, spots):\n",
    "        immediate_exercise_value = payoff_fn(spots)\n",
    "        return tf.where(is_american,\n",
    "                        tf.math.maximum(immediate_exercise_value, values), values)\n",
    "\n",
    "    return modifier\n",
    "\n",
    "\n",
    "def option_price_binomial(*,\n",
    "                          volatilities,\n",
    "                          strikes,\n",
    "                          expiries,\n",
    "                          spots,\n",
    "                          discount_rates=None,\n",
    "                          dividend_rates=None,\n",
    "                          is_call_options=None,\n",
    "                          is_american=None,\n",
    "                          num_steps=100,\n",
    "                          dtype=None,\n",
    "                          name=None):\n",
    "    \"\"\"Computes the BS price for a batch of European or American options.\n",
    "\n",
    "    Uses the Cox-Ross-Rubinstein version of the binomial tree method to compute\n",
    "    the price of American or European options. Supports batching of the options\n",
    "    and allows mixing of European and American style exercises in a batch.\n",
    "    For more information about the binomial tree method and the\n",
    "    Cox-Ross-Rubinstein method in particular see the references below.\n",
    "\n",
    "    #### Example\n",
    "\n",
    "    ```python\n",
    "    # Prices 5 options with a mix of Call/Put, American/European features\n",
    "    # in a single batch.\n",
    "    dtype = np.float64\n",
    "    spots = np.array([1.0, 2.0, 3.0, 4.0, 5.0], dtype=dtype)\n",
    "    strikes = np.array([3.0, 3.0, 3.0, 3.0, 3.0], dtype=dtype)\n",
    "    volatilities = np.array([0.1, 0.22, 0.32, 0.01, 0.4], dtype=dtype)\n",
    "    is_call_options = np.array([True, True, False, False, False])\n",
    "    is_american = np.array([False, True, True, False, True])\n",
    "    discount_rates = np.array(0.035, dtype=dtype)\n",
    "    dividend_rates = np.array([0.02, 0.0, 0.07, 0.01, 0.0], dtype=dtype)\n",
    "    expiries = np.array(1.0, dtype=dtype)\n",
    "\n",
    "    prices = option_price_binomial(\n",
    "        volatilities=volatilities,\n",
    "        strikes=strikes,\n",
    "        expiries=expiries,\n",
    "        spots=spots,\n",
    "        discount_rates=discount_rates,\n",
    "        dividend_rates=dividend_rates,\n",
    "        is_call_options=is_call_options,\n",
    "        is_american=is_american,\n",
    "        dtype=dtype)\n",
    "    # Prints [0., 0.0098847, 0.41299509, 0., 0.06046989]\n",
    "    ```\n",
    "\n",
    "    #### References\n",
    "\n",
    "    [1] Hull, John C., Options, Futures and Other Derivatives. Pearson, 2018.\n",
    "    [2] Wikipedia contributors. Binomial Options Pricing Model. Available at:\n",
    "      https://en.wikipedia.org/wiki/Binomial_options_pricing_model\n",
    "\n",
    "    Args:\n",
    "      volatilities: Real `Tensor` of any shape and dtype. The volatilities to\n",
    "        expiry of the options to price.\n",
    "      strikes: A real `Tensor` of the same dtype and compatible shape as\n",
    "        `volatilities`. The strikes of the options to be priced.\n",
    "      expiries: A real `Tensor` of same dtype and compatible shape as\n",
    "        `volatilities`. The expiry of each option. The units should be such that\n",
    "        `expiry * volatility**2` is dimensionless.\n",
    "      spots: A real `Tensor` of any shape that broadcasts to the shape of the\n",
    "        `volatilities`. The current spot price of the underlying.\n",
    "      discount_rates: An optional real `Tensor` of same dtype as the\n",
    "        `volatilities`. The risk free discount rate. If None the rate is assumed\n",
    "        to be 0.\n",
    "        Default value: None, equivalent to discount rates = 0..\n",
    "      dividend_rates: An optional real `Tensor` of same dtype as the\n",
    "        `volatilities`. If None the rate is assumed to be 0.\n",
    "        Default value: None, equivalent to discount rates = 1.\n",
    "      is_call_options: A boolean `Tensor` of a shape compatible with\n",
    "        `volatilities`. Indicates whether the option is a call (if True) or a put\n",
    "        (if False). If not supplied, call options are assumed.\n",
    "        Default value: None, equivalent to is_call_options = True.\n",
    "      is_american: A boolean `Tensor` of a shape compatible with `volatilities`.\n",
    "        Indicates whether the option exercise style is American (if True) or\n",
    "        European (if False). If not supplied, European style exercise is assumed.\n",
    "        Default value: None, equivalent to is_american = False.\n",
    "      num_steps: A positive scalar int32 `Tensor`. The size of the time\n",
    "        discretization to use.\n",
    "        Default value: 100.\n",
    "      dtype: Optional `tf.DType`. If supplied, the dtype to be used for conversion\n",
    "        of any supplied non-`Tensor` arguments to `Tensor`.\n",
    "        Default value: None which maps to the default dtype inferred by TensorFlow\n",
    "          (float32).\n",
    "      name: str. The name for the ops created by this function.\n",
    "        Default value: None which is mapped to the default name `option_price`.\n",
    "\n",
    "    Returns:\n",
    "      A `Tensor` of the same shape as the inferred batch shape of the input data.\n",
    "      The Black Scholes price of the options computed on a binomial tree.\n",
    "    \"\"\"\n",
    "    with tf.name_scope(name or 'crr_option_price'):\n",
    "        strikes = tf.convert_to_tensor(strikes, dtype=dtype, name='strikes')\n",
    "        dtype = strikes.dtype\n",
    "        volatilities = tf.convert_to_tensor(\n",
    "            volatilities, dtype=dtype, name='volatilities')\n",
    "        expiries = tf.convert_to_tensor(expiries, dtype=dtype, name='expiries')\n",
    "        spots = tf.convert_to_tensor(spots, dtype=dtype, name='spots')\n",
    "\n",
    "        if discount_rates is None:\n",
    "            discount_rates = tf.zeros_like(volatilities)\n",
    "        else:\n",
    "            discount_rates = tf.convert_to_tensor(\n",
    "                discount_rates, dtype=dtype, name='discount_rates')\n",
    "        if dividend_rates is None:\n",
    "            dividend_rates = tf.zeros_like(volatilities)\n",
    "        else:\n",
    "            dividend_rates = tf.convert_to_tensor(\n",
    "                dividend_rates, dtype=dtype, name='dividend_rates')\n",
    "        if is_call_options is None:\n",
    "            is_call_options = tf.ones_like(\n",
    "                volatilities, dtype=tf.bool, name='is_call_options')\n",
    "        else:\n",
    "            is_call_options = tf.convert_to_tensor(\n",
    "                is_call_options, dtype=tf.bool, name='is_call_options')\n",
    "        if is_american is None:\n",
    "            is_american = tf.zeros_like(\n",
    "                volatilities, dtype=tf.bool, name='is_american')\n",
    "        else:\n",
    "            is_american = tf.convert_to_tensor(\n",
    "                is_american, dtype=tf.bool, name='is_american')\n",
    "\n",
    "        num_steps = tf.cast(num_steps, dtype=dtype)\n",
    "        dt = expiries / num_steps\n",
    "\n",
    "        # CRR choices for the up and down move multipliers\n",
    "        ln_up = volatilities * tf.math.sqrt(dt)\n",
    "        ln_dn = -ln_up\n",
    "\n",
    "        # Prepares the spot grid.\n",
    "        grid_idx = tf.range(num_steps + 1)\n",
    "        # Stores the grid as shape [input_batch, N + 1] where N = num_steps.\n",
    "        log_spot_grid_1 = tf.expand_dims(\n",
    "            tf.math.log(spots) + ln_up * num_steps, axis=-1)\n",
    "        log_spot_grid_2 = tf.expand_dims(ln_dn - ln_up, axis=-1) * grid_idx\n",
    "        log_spot_grid = log_spot_grid_1 + log_spot_grid_2\n",
    "\n",
    "        # Adding the new dimension is to ensure that batch shape is at the front.\n",
    "        payoff_fn = _get_payoff_fn(\n",
    "            tf.expand_dims(strikes, axis=-1),\n",
    "            tf.expand_dims(is_call_options, axis=-1))\n",
    "        value_mod_fn = _get_value_modifier(\n",
    "            tf.expand_dims(is_american, axis=-1), payoff_fn)\n",
    "\n",
    "        # Shape [batch shape, num time steps + 1]\n",
    "        values_grid = payoff_fn(tf.math.exp(log_spot_grid))\n",
    "\n",
    "        p_up = tf.math.exp((discount_rates - dividend_rates) * dt + ln_up) - 1\n",
    "        p_up /= tf.math.exp(2 * ln_up) - 1\n",
    "        p_up = tf.expand_dims(p_up, axis=-1)\n",
    "        p_dn = 1 - p_up\n",
    "        discount_factors = tf.expand_dims(\n",
    "            tf.math.exp(-discount_rates * dt), axis=-1)\n",
    "        ln_up = tf.expand_dims(ln_up, axis=-1)\n",
    "\n",
    "        def one_step_back(current_values, current_log_spot_grid):\n",
    "            next_values = (current_values[..., 1:] * p_dn\n",
    "                           + current_values[..., :-1] * p_up)\n",
    "            next_log_spot_grid = current_log_spot_grid[..., :-1] - ln_up\n",
    "            next_values = value_mod_fn(\n",
    "                next_values, tf.math.exp(next_log_spot_grid))\n",
    "            return discount_factors * next_values, next_log_spot_grid\n",
    "\n",
    "        def should_continue(current_values, current_log_spot_grid):\n",
    "            del current_values, current_log_spot_grid\n",
    "            return True\n",
    "\n",
    "        batch_shape = values_grid.shape[:-1]\n",
    "        pv, _ = tf.while_loop(\n",
    "            should_continue,\n",
    "            one_step_back, (values_grid, log_spot_grid),\n",
    "            maximum_iterations=tf.cast(num_steps, dtype=tf.int32),\n",
    "            shape_invariants=(tf.TensorShape(batch_shape + [None]),\n",
    "                              tf.TensorShape(batch_shape + [None])))\n",
    "        return tf.where(\n",
    "            expiries > 0,\n",
    "            tf.squeeze(pv, axis=-1),\n",
    "            tf.where(is_call_options,\n",
    "                     tf.math.maximum(spots - strikes, 0),\n",
    "                     tf.math.maximum(strikes - spots, 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 560,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.1699267589940286, 0.22419338410832115, 0.27947430480342916, 0.3350718963982805, 0.3907371360544206, 0.4463589186673278, 0.5018749896652677, 0.5572363255359198, 0.6123942932159053, 0.6673005523763282, 0.7219052333521736, 0.776162744472108, 0.8300287327698597, 0.8834658721052184, 0.9364377846765696, 0.9889081466594429, 1.0408480849646695, 1.0922265807867197, 1.1430165411350965, 1.1931903646279234, 1.2427291720106817, 1.291603605773916, 1.339790756501213, 1.387275286714091, 1.4340390849318905, 1.4800596333505922, 1.5253240154592846, 1.5698174654680344, 1.6135241157526323, 1.6564328711166654, 1.6985321302942271, 1.7398117684361327, 1.7802637884970618, 1.8198792816149245, 1.8586521678618269, 1.8965804962225965, 1.9336568537868042, 1.969878056707479, 2.0052458176720185, 2.0397587672670374, 2.0734164203007333, 2.106220060976816, 2.1381731773956556, 2.1692798133666504, 2.199543674124456, 2.2289719642530557, 2.2575699847630193, 2.2853443050259523, 2.31230183219203, 2.3384539607824784, 2.3638095271432356, 2.38837643031643, 2.4121685326352633, 2.4351950214409324, 2.457468272237595, 2.4790032855997266, 2.4998094761164396, 2.5199034313663224, 2.5392955343958103, 2.558004097926335, 2.5760384611512523, 2.593414708774123, 2.6101477288494905, 2.626253668679873, 2.6417481028718095, 2.656646072043469, 2.6709632816629423, 2.6847139247714615, 2.6979159732567726, 2.7105850707877415, 2.722737969813403, 2.734387862069023, 2.7455499851180187, 2.7562383795371206, 2.7664693029228062, 2.7762547322458215, 2.7856105718610857, 2.7945528616829054, 2.8030967528606556, 2.811256165170745, 2.819045247526725, 2.8264801601285154, 2.8335741182432552, 2.840341817319484, 2.8467971672419767, 2.8529526107198016, 2.8588190303230627, 2.8644016344897225, 2.869712497963983, 2.874762857703007, 2.8795637355839636, 2.8841274395152414, 2.8884639255066937, 2.89258349600104, 2.8964967716518757, 2.900216551510645, 2.9037506464860035, 2.9071111966023637, 2.9103106664655525, 2.913361876544747]\n"
     ]
    }
   ],
   "source": [
    "f = open(\"training.csv\", \"w\")\n",
    "res = []\n",
    "v = 0.05\n",
    "for i in range(100):\n",
    "    v += 0.05\n",
    "    res.append(np.float64(option_price_binomial(volatilities=v,\n",
    "                          strikes=3.0,\n",
    "                          expiries=1.0,\n",
    "                          spots=3.0,\n",
    "                          discount_rates=0.035,\n",
    "                          dividend_rates=0.07,\n",
    "                          is_call_options=False,\n",
    "                          is_american=True,\n",
    "                          num_steps=100,\n",
    "                          dtype=np.float64)))\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 561,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax1 = plt.subplots()\n",
    "ax1.plot(res, color='r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extend feature set\n",
    "\n",
    "We need to extend the feature set to cover the option style, Call or Put and early exercise or not, American or European\n",
    "\n",
    "These string features needed encoding as numerical values so they can be passed to the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate features without type and style.\n",
    "vols, mats, spots, strikes, rates = parameter_scenarios(num_steps=20)\n",
    "X = generate_model_scenarios(spot=spots, strike=strikes, mat=mats, rate=rates, vol=vols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create all combinations with option type\n",
    "# Call = 0, Put = 1\n",
    "X = combinations(X, [0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create all combinations with option style\n",
    "# American (early exercise) = 0, European = 1\n",
    "X = combinations(X, [0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle the training data\n",
    "Xs = shuffle(X, random_state=42)\n",
    "#scaler = MinMaxScaler(feature_range=(0, 1),copy=False).fit(Xs)\n",
    "#Xss = scaler.transform(Xs)\n",
    "dfxs = pd.DataFrame(Xs, columns=['spot', 'strike', 'maturity', 'rate', 'volatility','call_put','amer_eur'])\n",
    "dfxs.to_csv('XFull.csv', encoding='ascii', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 563,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_scenarios(X_train):\n",
    "\n",
    "    res = []\n",
    "    for scen in X_train:\n",
    "        S, K, T, r, v, cp, ae = np.round(scen, 8)\n",
    "        value = np.round(option_price_binomial(volatilities=v,\n",
    "                                               strikes=K,\n",
    "                                               expiries=T,\n",
    "                                               spots=S,\n",
    "                                               discount_rates=r,\n",
    "                                               dividend_rates=0.0,\n",
    "                                               is_call_options=not (bool(cp)),\n",
    "                                               is_american=not (bool(ae)),\n",
    "                                               num_steps=200,\n",
    "                                               dtype=np.float64), 8)\n",
    "        res.append([S, K, T, r, v, cp, ae, value])\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new CSV file for results and write a header row.\n",
    "f = open(\"binomial_training.csv\", \"w\")\n",
    "f.write(f\"Spot, Strike, Maturity, rate, volatility, isPut, isEuropean\\n\")\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 565,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57000 of 12800000\n",
      "57500 of 12800000\n",
      "58000 of 12800000\n",
      "58500 of 12800000\n",
      "59000 of 12800000\n",
      "59500 of 12800000\n",
      "60000 of 12800000\n",
      "60500 of 12800000\n",
      "61000 of 12800000\n",
      "61500 of 12800000\n",
      "62000 of 12800000\n",
      "62500 of 12800000\n",
      "63000 of 12800000\n",
      "63500 of 12800000\n",
      "64000 of 12800000\n",
      "64500 of 12800000\n",
      "65000 of 12800000\n",
      "65500 of 12800000\n",
      "66000 of 12800000\n",
      "66500 of 12800000\n",
      "67000 of 12800000\n",
      "67500 of 12800000\n",
      "68000 of 12800000\n",
      "68500 of 12800000\n",
      "69000 of 12800000\n",
      "69500 of 12800000\n",
      "70000 of 12800000\n",
      "70500 of 12800000\n",
      "71000 of 12800000\n",
      "71500 of 12800000\n",
      "72000 of 12800000\n",
      "72500 of 12800000\n",
      "73000 of 12800000\n",
      "73500 of 12800000\n",
      "74000 of 12800000\n",
      "74500 of 12800000\n",
      "75000 of 12800000\n",
      "75500 of 12800000\n",
      "76000 of 12800000\n",
      "76500 of 12800000\n",
      "77000 of 12800000\n",
      "77500 of 12800000\n",
      "78000 of 12800000\n",
      "78500 of 12800000\n",
      "79000 of 12800000\n",
      "79500 of 12800000\n",
      "80000 of 12800000\n",
      "80500 of 12800000\n",
      "81000 of 12800000\n",
      "81500 of 12800000\n",
      "82000 of 12800000\n",
      "82500 of 12800000\n",
      "83000 of 12800000\n",
      "83500 of 12800000\n",
      "84000 of 12800000\n",
      "84500 of 12800000\n",
      "85000 of 12800000\n",
      "85500 of 12800000\n",
      "86000 of 12800000\n",
      "86500 of 12800000\n",
      "87000 of 12800000\n",
      "87500 of 12800000\n",
      "88000 of 12800000\n",
      "88500 of 12800000\n",
      "89000 of 12800000\n",
      "89500 of 12800000\n",
      "90000 of 12800000\n",
      "90500 of 12800000\n",
      "91000 of 12800000\n",
      "91500 of 12800000\n",
      "92000 of 12800000\n",
      "92500 of 12800000\n",
      "93000 of 12800000\n",
      "93500 of 12800000\n",
      "94000 of 12800000\n",
      "94500 of 12800000\n",
      "95000 of 12800000\n",
      "95500 of 12800000\n",
      "96000 of 12800000\n",
      "96500 of 12800000\n",
      "97000 of 12800000\n",
      "97500 of 12800000\n",
      "98000 of 12800000\n",
      "98500 of 12800000\n",
      "99000 of 12800000\n",
      "99500 of 12800000\n",
      "100000 of 12800000\n",
      "100500 of 12800000\n",
      "101000 of 12800000\n",
      "101500 of 12800000\n",
      "102000 of 12800000\n",
      "102500 of 12800000\n",
      "103000 of 12800000\n",
      "103500 of 12800000\n",
      "104000 of 12800000\n",
      "104500 of 12800000\n",
      "105000 of 12800000\n",
      "105500 of 12800000\n",
      "106000 of 12800000\n",
      "106500 of 12800000\n",
      "107000 of 12800000\n",
      "107500 of 12800000\n",
      "108000 of 12800000\n",
      "108500 of 12800000\n",
      "109000 of 12800000\n",
      "109500 of 12800000\n",
      "110000 of 12800000\n",
      "110500 of 12800000\n",
      "111000 of 12800000\n",
      "111500 of 12800000\n",
      "112000 of 12800000\n",
      "112500 of 12800000\n",
      "113000 of 12800000\n",
      "113500 of 12800000\n",
      "114000 of 12800000\n",
      "114500 of 12800000\n",
      "115000 of 12800000\n",
      "115500 of 12800000\n",
      "116000 of 12800000\n",
      "116500 of 12800000\n",
      "117000 of 12800000\n",
      "117500 of 12800000\n",
      "118000 of 12800000\n",
      "118500 of 12800000\n",
      "119000 of 12800000\n",
      "119500 of 12800000\n",
      "120000 of 12800000\n",
      "120500 of 12800000\n",
      "121000 of 12800000\n",
      "121500 of 12800000\n",
      "122000 of 12800000\n",
      "122500 of 12800000\n",
      "123000 of 12800000\n",
      "123500 of 12800000\n",
      "124000 of 12800000\n",
      "124500 of 12800000\n",
      "125000 of 12800000\n",
      "125500 of 12800000\n",
      "126000 of 12800000\n",
      "126500 of 12800000\n",
      "127000 of 12800000\n",
      "127500 of 12800000\n",
      "128000 of 12800000\n",
      "128500 of 12800000\n",
      "129000 of 12800000\n",
      "129500 of 12800000\n",
      "130000 of 12800000\n",
      "130500 of 12800000\n",
      "131000 of 12800000\n",
      "131500 of 12800000\n",
      "132000 of 12800000\n",
      "132500 of 12800000\n",
      "133000 of 12800000\n",
      "133500 of 12800000\n",
      "134000 of 12800000\n",
      "134500 of 12800000\n",
      "135000 of 12800000\n",
      "135500 of 12800000\n",
      "136000 of 12800000\n",
      "136500 of 12800000\n",
      "137000 of 12800000\n",
      "137500 of 12800000\n",
      "138000 of 12800000\n",
      "138500 of 12800000\n",
      "139000 of 12800000\n",
      "139500 of 12800000\n",
      "140000 of 12800000\n",
      "140500 of 12800000\n",
      "141000 of 12800000\n",
      "141500 of 12800000\n",
      "142000 of 12800000\n",
      "142500 of 12800000\n",
      "143000 of 12800000\n",
      "143500 of 12800000\n",
      "144000 of 12800000\n",
      "144500 of 12800000\n",
      "145000 of 12800000\n",
      "145500 of 12800000\n",
      "146000 of 12800000\n",
      "146500 of 12800000\n",
      "147000 of 12800000\n",
      "147500 of 12800000\n",
      "148000 of 12800000\n",
      "148500 of 12800000\n",
      "149000 of 12800000\n",
      "149500 of 12800000\n",
      "150000 of 12800000\n",
      "150500 of 12800000\n",
      "151000 of 12800000\n",
      "151500 of 12800000\n",
      "152000 of 12800000\n",
      "152500 of 12800000\n",
      "153000 of 12800000\n",
      "153500 of 12800000\n",
      "154000 of 12800000\n",
      "154500 of 12800000\n",
      "155000 of 12800000\n",
      "155500 of 12800000\n",
      "156000 of 12800000\n",
      "156500 of 12800000\n",
      "157000 of 12800000\n",
      "157500 of 12800000\n",
      "158000 of 12800000\n",
      "158500 of 12800000\n",
      "159000 of 12800000\n",
      "159500 of 12800000\n",
      "160000 of 12800000\n",
      "160500 of 12800000\n",
      "161000 of 12800000\n",
      "161500 of 12800000\n",
      "162000 of 12800000\n",
      "162500 of 12800000\n",
      "163000 of 12800000\n",
      "163500 of 12800000\n",
      "164000 of 12800000\n",
      "164500 of 12800000\n",
      "165000 of 12800000\n",
      "165500 of 12800000\n",
      "166000 of 12800000\n",
      "166500 of 12800000\n",
      "167000 of 12800000\n",
      "167500 of 12800000\n",
      "168000 of 12800000\n",
      "168500 of 12800000\n",
      "169000 of 12800000\n",
      "169500 of 12800000\n",
      "170000 of 12800000\n",
      "170500 of 12800000\n",
      "171000 of 12800000\n",
      "171500 of 12800000\n",
      "172000 of 12800000\n",
      "172500 of 12800000\n",
      "173000 of 12800000\n",
      "173500 of 12800000\n",
      "174000 of 12800000\n",
      "174500 of 12800000\n",
      "175000 of 12800000\n",
      "175500 of 12800000\n",
      "176000 of 12800000\n",
      "176500 of 12800000\n",
      "177000 of 12800000\n",
      "177500 of 12800000\n",
      "178000 of 12800000\n",
      "178500 of 12800000\n",
      "179000 of 12800000\n",
      "179500 of 12800000\n",
      "180000 of 12800000\n",
      "180500 of 12800000\n",
      "181000 of 12800000\n",
      "181500 of 12800000\n",
      "182000 of 12800000\n",
      "182500 of 12800000\n",
      "183000 of 12800000\n",
      "183500 of 12800000\n",
      "184000 of 12800000\n",
      "184500 of 12800000\n",
      "185000 of 12800000\n",
      "185500 of 12800000\n",
      "186000 of 12800000\n",
      "186500 of 12800000\n",
      "187000 of 12800000\n",
      "187500 of 12800000\n",
      "188000 of 12800000\n",
      "188500 of 12800000\n",
      "189000 of 12800000\n",
      "189500 of 12800000\n",
      "190000 of 12800000\n",
      "190500 of 12800000\n",
      "191000 of 12800000\n",
      "191500 of 12800000\n",
      "192000 of 12800000\n",
      "192500 of 12800000\n",
      "193000 of 12800000\n",
      "193500 of 12800000\n",
      "194000 of 12800000\n",
      "194500 of 12800000\n",
      "195000 of 12800000\n",
      "195500 of 12800000\n",
      "196000 of 12800000\n",
      "196500 of 12800000\n",
      "197000 of 12800000\n",
      "197500 of 12800000\n",
      "198000 of 12800000\n",
      "198500 of 12800000\n",
      "199000 of 12800000\n",
      "199500 of 12800000\n",
      "200000 of 12800000\n",
      "200500 of 12800000\n",
      "201000 of 12800000\n",
      "201500 of 12800000\n",
      "202000 of 12800000\n",
      "202500 of 12800000\n",
      "203000 of 12800000\n",
      "203500 of 12800000\n",
      "204000 of 12800000\n",
      "204500 of 12800000\n",
      "205000 of 12800000\n",
      "205500 of 12800000\n",
      "206000 of 12800000\n",
      "206500 of 12800000\n",
      "207000 of 12800000\n",
      "207500 of 12800000\n",
      "208000 of 12800000\n",
      "208500 of 12800000\n",
      "209000 of 12800000\n",
      "209500 of 12800000\n",
      "210000 of 12800000\n",
      "210500 of 12800000\n",
      "211000 of 12800000\n",
      "211500 of 12800000\n",
      "212000 of 12800000\n",
      "212500 of 12800000\n",
      "213000 of 12800000\n",
      "213500 of 12800000\n",
      "214000 of 12800000\n",
      "214500 of 12800000\n",
      "215000 of 12800000\n",
      "215500 of 12800000\n",
      "216000 of 12800000\n",
      "216500 of 12800000\n",
      "217000 of 12800000\n",
      "217500 of 12800000\n",
      "218000 of 12800000\n",
      "218500 of 12800000\n",
      "219000 of 12800000\n",
      "219500 of 12800000\n",
      "220000 of 12800000\n",
      "220500 of 12800000\n",
      "221000 of 12800000\n",
      "221500 of 12800000\n",
      "222000 of 12800000\n",
      "222500 of 12800000\n",
      "223000 of 12800000\n",
      "223500 of 12800000\n",
      "224000 of 12800000\n",
      "224500 of 12800000\n",
      "225000 of 12800000\n",
      "225500 of 12800000\n",
      "226000 of 12800000\n",
      "226500 of 12800000\n",
      "227000 of 12800000\n",
      "227500 of 12800000\n",
      "228000 of 12800000\n",
      "228500 of 12800000\n",
      "229000 of 12800000\n",
      "229500 of 12800000\n",
      "230000 of 12800000\n",
      "230500 of 12800000\n",
      "231000 of 12800000\n",
      "231500 of 12800000\n",
      "232000 of 12800000\n",
      "232500 of 12800000\n",
      "233000 of 12800000\n",
      "233500 of 12800000\n",
      "234000 of 12800000\n",
      "234500 of 12800000\n",
      "235000 of 12800000\n",
      "235500 of 12800000\n",
      "236000 of 12800000\n",
      "236500 of 12800000\n",
      "237000 of 12800000\n",
      "237500 of 12800000\n",
      "238000 of 12800000\n",
      "238500 of 12800000\n",
      "239000 of 12800000\n",
      "239500 of 12800000\n",
      "240000 of 12800000\n",
      "240500 of 12800000\n",
      "241000 of 12800000\n",
      "241500 of 12800000\n",
      "242000 of 12800000\n",
      "242500 of 12800000\n",
      "243000 of 12800000\n",
      "243500 of 12800000\n",
      "244000 of 12800000\n",
      "244500 of 12800000\n",
      "245000 of 12800000\n",
      "245500 of 12800000\n",
      "246000 of 12800000\n",
      "246500 of 12800000\n",
      "247000 of 12800000\n",
      "247500 of 12800000\n",
      "248000 of 12800000\n",
      "248500 of 12800000\n",
      "249000 of 12800000\n",
      "249500 of 12800000\n",
      "250000 of 12800000\n",
      "250500 of 12800000\n",
      "251000 of 12800000\n",
      "251500 of 12800000\n",
      "252000 of 12800000\n",
      "252500 of 12800000\n",
      "253000 of 12800000\n",
      "253500 of 12800000\n",
      "254000 of 12800000\n",
      "254500 of 12800000\n",
      "255000 of 12800000\n",
      "255500 of 12800000\n",
      "256000 of 12800000\n",
      "256500 of 12800000\n",
      "257000 of 12800000\n",
      "257500 of 12800000\n",
      "258000 of 12800000\n",
      "258500 of 12800000\n",
      "259000 of 12800000\n",
      "259500 of 12800000\n",
      "260000 of 12800000\n",
      "260500 of 12800000\n",
      "261000 of 12800000\n",
      "261500 of 12800000\n",
      "262000 of 12800000\n",
      "262500 of 12800000\n",
      "263000 of 12800000\n",
      "263500 of 12800000\n",
      "264000 of 12800000\n",
      "264500 of 12800000\n",
      "265000 of 12800000\n",
      "265500 of 12800000\n",
      "266000 of 12800000\n",
      "266500 of 12800000\n",
      "267000 of 12800000\n",
      "267500 of 12800000\n",
      "268000 of 12800000\n",
      "268500 of 12800000\n",
      "269000 of 12800000\n",
      "269500 of 12800000\n",
      "270000 of 12800000\n",
      "270500 of 12800000\n",
      "271000 of 12800000\n",
      "271500 of 12800000\n",
      "272000 of 12800000\n",
      "272500 of 12800000\n",
      "273000 of 12800000\n",
      "273500 of 12800000\n",
      "274000 of 12800000\n",
      "274500 of 12800000\n",
      "275000 of 12800000\n",
      "275500 of 12800000\n",
      "276000 of 12800000\n",
      "276500 of 12800000\n",
      "277000 of 12800000\n",
      "277500 of 12800000\n",
      "278000 of 12800000\n",
      "278500 of 12800000\n",
      "279000 of 12800000\n",
      "279500 of 12800000\n",
      "280000 of 12800000\n",
      "280500 of 12800000\n",
      "281000 of 12800000\n",
      "281500 of 12800000\n",
      "282000 of 12800000\n",
      "282500 of 12800000\n",
      "283000 of 12800000\n",
      "283500 of 12800000\n",
      "284000 of 12800000\n",
      "284500 of 12800000\n",
      "285000 of 12800000\n",
      "285500 of 12800000\n",
      "286000 of 12800000\n",
      "286500 of 12800000\n",
      "287000 of 12800000\n",
      "287500 of 12800000\n",
      "288000 of 12800000\n",
      "288500 of 12800000\n",
      "289000 of 12800000\n",
      "289500 of 12800000\n",
      "290000 of 12800000\n",
      "290500 of 12800000\n",
      "291000 of 12800000\n",
      "291500 of 12800000\n",
      "292000 of 12800000\n",
      "292500 of 12800000\n",
      "293000 of 12800000\n",
      "293500 of 12800000\n",
      "294000 of 12800000\n",
      "294500 of 12800000\n",
      "295000 of 12800000\n",
      "295500 of 12800000\n",
      "296000 of 12800000\n",
      "296500 of 12800000\n",
      "297000 of 12800000\n",
      "297500 of 12800000\n",
      "298000 of 12800000\n",
      "298500 of 12800000\n",
      "299000 of 12800000\n",
      "299500 of 12800000\n",
      "300000 of 12800000\n",
      "300500 of 12800000\n",
      "301000 of 12800000\n",
      "301500 of 12800000\n",
      "302000 of 12800000\n",
      "302500 of 12800000\n",
      "303000 of 12800000\n",
      "303500 of 12800000\n",
      "304000 of 12800000\n",
      "304500 of 12800000\n",
      "305000 of 12800000\n",
      "305500 of 12800000\n",
      "306000 of 12800000\n",
      "306500 of 12800000\n",
      "307000 of 12800000\n",
      "307500 of 12800000\n",
      "308000 of 12800000\n",
      "308500 of 12800000\n",
      "309000 of 12800000\n",
      "309500 of 12800000\n",
      "310000 of 12800000\n",
      "310500 of 12800000\n",
      "311000 of 12800000\n",
      "311500 of 12800000\n",
      "312000 of 12800000\n",
      "312500 of 12800000\n",
      "313000 of 12800000\n",
      "313500 of 12800000\n",
      "314000 of 12800000\n",
      "314500 of 12800000\n",
      "315000 of 12800000\n",
      "315500 of 12800000\n",
      "316000 of 12800000\n",
      "316500 of 12800000\n",
      "317000 of 12800000\n",
      "317500 of 12800000\n",
      "318000 of 12800000\n",
      "318500 of 12800000\n",
      "319000 of 12800000\n",
      "319500 of 12800000\n",
      "320000 of 12800000\n",
      "320500 of 12800000\n",
      "321000 of 12800000\n",
      "321500 of 12800000\n",
      "322000 of 12800000\n",
      "322500 of 12800000\n",
      "323000 of 12800000\n",
      "323500 of 12800000\n",
      "324000 of 12800000\n",
      "324500 of 12800000\n",
      "325000 of 12800000\n",
      "325500 of 12800000\n",
      "326000 of 12800000\n",
      "326500 of 12800000\n",
      "327000 of 12800000\n",
      "327500 of 12800000\n",
      "328000 of 12800000\n",
      "328500 of 12800000\n",
      "329000 of 12800000\n",
      "329500 of 12800000\n",
      "330000 of 12800000\n",
      "330500 of 12800000\n",
      "331000 of 12800000\n",
      "331500 of 12800000\n",
      "332000 of 12800000\n",
      "332500 of 12800000\n",
      "333000 of 12800000\n",
      "333500 of 12800000\n",
      "334000 of 12800000\n",
      "334500 of 12800000\n",
      "335000 of 12800000\n",
      "335500 of 12800000\n",
      "336000 of 12800000\n",
      "336500 of 12800000\n",
      "337000 of 12800000\n",
      "337500 of 12800000\n",
      "338000 of 12800000\n",
      "338500 of 12800000\n",
      "339000 of 12800000\n",
      "339500 of 12800000\n",
      "340000 of 12800000\n",
      "340500 of 12800000\n",
      "341000 of 12800000\n",
      "341500 of 12800000\n",
      "342000 of 12800000\n",
      "342500 of 12800000\n",
      "343000 of 12800000\n",
      "343500 of 12800000\n",
      "344000 of 12800000\n",
      "344500 of 12800000\n",
      "345000 of 12800000\n",
      "345500 of 12800000\n",
      "346000 of 12800000\n",
      "346500 of 12800000\n",
      "347000 of 12800000\n",
      "347500 of 12800000\n",
      "348000 of 12800000\n",
      "348500 of 12800000\n",
      "349000 of 12800000\n",
      "349500 of 12800000\n",
      "350000 of 12800000\n",
      "350500 of 12800000\n",
      "351000 of 12800000\n",
      "351500 of 12800000\n",
      "352000 of 12800000\n",
      "352500 of 12800000\n",
      "353000 of 12800000\n",
      "353500 of 12800000\n",
      "354000 of 12800000\n",
      "354500 of 12800000\n",
      "355000 of 12800000\n",
      "355500 of 12800000\n",
      "356000 of 12800000\n",
      "356500 of 12800000\n",
      "357000 of 12800000\n",
      "357500 of 12800000\n",
      "358000 of 12800000\n",
      "358500 of 12800000\n",
      "359000 of 12800000\n",
      "359500 of 12800000\n",
      "360000 of 12800000\n",
      "360500 of 12800000\n",
      "361000 of 12800000\n",
      "361500 of 12800000\n",
      "362000 of 12800000\n",
      "362500 of 12800000\n",
      "363000 of 12800000\n",
      "363500 of 12800000\n",
      "364000 of 12800000\n",
      "364500 of 12800000\n",
      "365000 of 12800000\n",
      "365500 of 12800000\n",
      "366000 of 12800000\n",
      "366500 of 12800000\n",
      "367000 of 12800000\n",
      "367500 of 12800000\n",
      "368000 of 12800000\n",
      "368500 of 12800000\n",
      "369000 of 12800000\n",
      "369500 of 12800000\n",
      "370000 of 12800000\n",
      "370500 of 12800000\n",
      "371000 of 12800000\n",
      "371500 of 12800000\n",
      "372000 of 12800000\n",
      "372500 of 12800000\n",
      "373000 of 12800000\n",
      "373500 of 12800000\n",
      "374000 of 12800000\n",
      "374500 of 12800000\n",
      "375000 of 12800000\n",
      "375500 of 12800000\n",
      "376000 of 12800000\n",
      "376500 of 12800000\n",
      "377000 of 12800000\n",
      "377500 of 12800000\n",
      "378000 of 12800000\n",
      "378500 of 12800000\n",
      "379000 of 12800000\n",
      "379500 of 12800000\n",
      "380000 of 12800000\n",
      "380500 of 12800000\n",
      "381000 of 12800000\n",
      "381500 of 12800000\n",
      "382000 of 12800000\n",
      "382500 of 12800000\n",
      "383000 of 12800000\n",
      "383500 of 12800000\n",
      "384000 of 12800000\n",
      "384500 of 12800000\n",
      "385000 of 12800000\n",
      "385500 of 12800000\n",
      "386000 of 12800000\n",
      "386500 of 12800000\n",
      "387000 of 12800000\n",
      "387500 of 12800000\n",
      "388000 of 12800000\n",
      "388500 of 12800000\n",
      "389000 of 12800000\n",
      "389500 of 12800000\n",
      "390000 of 12800000\n",
      "390500 of 12800000\n",
      "391000 of 12800000\n",
      "391500 of 12800000\n",
      "392000 of 12800000\n",
      "392500 of 12800000\n",
      "393000 of 12800000\n",
      "393500 of 12800000\n",
      "394000 of 12800000\n",
      "394500 of 12800000\n",
      "395000 of 12800000\n",
      "395500 of 12800000\n",
      "396000 of 12800000\n",
      "396500 of 12800000\n",
      "397000 of 12800000\n",
      "397500 of 12800000\n",
      "398000 of 12800000\n",
      "398500 of 12800000\n",
      "399000 of 12800000\n",
      "399500 of 12800000\n",
      "400000 of 12800000\n",
      "400500 of 12800000\n",
      "401000 of 12800000\n",
      "401500 of 12800000\n",
      "402000 of 12800000\n",
      "402500 of 12800000\n",
      "403000 of 12800000\n",
      "403500 of 12800000\n",
      "404000 of 12800000\n",
      "404500 of 12800000\n",
      "405000 of 12800000\n",
      "405500 of 12800000\n",
      "406000 of 12800000\n",
      "406500 of 12800000\n",
      "407000 of 12800000\n",
      "407500 of 12800000\n",
      "408000 of 12800000\n",
      "408500 of 12800000\n",
      "409000 of 12800000\n",
      "409500 of 12800000\n",
      "410000 of 12800000\n",
      "410500 of 12800000\n",
      "411000 of 12800000\n",
      "411500 of 12800000\n",
      "412000 of 12800000\n",
      "412500 of 12800000\n",
      "413000 of 12800000\n",
      "413500 of 12800000\n",
      "414000 of 12800000\n",
      "414500 of 12800000\n",
      "415000 of 12800000\n",
      "415500 of 12800000\n",
      "416000 of 12800000\n",
      "416500 of 12800000\n",
      "417000 of 12800000\n",
      "417500 of 12800000\n",
      "418000 of 12800000\n",
      "418500 of 12800000\n",
      "419000 of 12800000\n",
      "419500 of 12800000\n",
      "420000 of 12800000\n",
      "420500 of 12800000\n",
      "421000 of 12800000\n",
      "421500 of 12800000\n",
      "422000 of 12800000\n",
      "422500 of 12800000\n",
      "423000 of 12800000\n",
      "423500 of 12800000\n",
      "424000 of 12800000\n",
      "424500 of 12800000\n",
      "425000 of 12800000\n",
      "425500 of 12800000\n",
      "426000 of 12800000\n",
      "426500 of 12800000\n",
      "427000 of 12800000\n",
      "427500 of 12800000\n",
      "428000 of 12800000\n",
      "428500 of 12800000\n",
      "429000 of 12800000\n",
      "429500 of 12800000\n",
      "430000 of 12800000\n",
      "430500 of 12800000\n",
      "431000 of 12800000\n",
      "431500 of 12800000\n",
      "432000 of 12800000\n",
      "432500 of 12800000\n",
      "433000 of 12800000\n",
      "433500 of 12800000\n",
      "434000 of 12800000\n",
      "434500 of 12800000\n",
      "435000 of 12800000\n",
      "435500 of 12800000\n",
      "436000 of 12800000\n",
      "436500 of 12800000\n",
      "437000 of 12800000\n",
      "437500 of 12800000\n",
      "438000 of 12800000\n",
      "438500 of 12800000\n",
      "439000 of 12800000\n",
      "439500 of 12800000\n",
      "440000 of 12800000\n",
      "440500 of 12800000\n",
      "441000 of 12800000\n",
      "441500 of 12800000\n",
      "442000 of 12800000\n",
      "442500 of 12800000\n",
      "443000 of 12800000\n",
      "443500 of 12800000\n",
      "444000 of 12800000\n",
      "444500 of 12800000\n",
      "445000 of 12800000\n",
      "445500 of 12800000\n",
      "446000 of 12800000\n",
      "446500 of 12800000\n",
      "447000 of 12800000\n",
      "447500 of 12800000\n",
      "448000 of 12800000\n",
      "448500 of 12800000\n",
      "449000 of 12800000\n",
      "449500 of 12800000\n",
      "450000 of 12800000\n",
      "450500 of 12800000\n",
      "451000 of 12800000\n",
      "451500 of 12800000\n",
      "452000 of 12800000\n",
      "452500 of 12800000\n",
      "453000 of 12800000\n",
      "453500 of 12800000\n",
      "454000 of 12800000\n",
      "454500 of 12800000\n",
      "455000 of 12800000\n",
      "455500 of 12800000\n",
      "456000 of 12800000\n",
      "456500 of 12800000\n",
      "457000 of 12800000\n",
      "457500 of 12800000\n",
      "458000 of 12800000\n",
      "458500 of 12800000\n",
      "459000 of 12800000\n",
      "459500 of 12800000\n",
      "460000 of 12800000\n",
      "460500 of 12800000\n",
      "461000 of 12800000\n",
      "461500 of 12800000\n",
      "462000 of 12800000\n",
      "462500 of 12800000\n",
      "463000 of 12800000\n",
      "463500 of 12800000\n",
      "464000 of 12800000\n",
      "464500 of 12800000\n",
      "465000 of 12800000\n",
      "465500 of 12800000\n",
      "466000 of 12800000\n",
      "466500 of 12800000\n",
      "467000 of 12800000\n",
      "467500 of 12800000\n",
      "468000 of 12800000\n",
      "468500 of 12800000\n",
      "469000 of 12800000\n",
      "469500 of 12800000\n",
      "470000 of 12800000\n",
      "470500 of 12800000\n",
      "471000 of 12800000\n",
      "471500 of 12800000\n",
      "472000 of 12800000\n",
      "472500 of 12800000\n",
      "473000 of 12800000\n",
      "473500 of 12800000\n",
      "474000 of 12800000\n",
      "474500 of 12800000\n",
      "475000 of 12800000\n",
      "475500 of 12800000\n",
      "476000 of 12800000\n",
      "476500 of 12800000\n",
      "477000 of 12800000\n",
      "477500 of 12800000\n",
      "478000 of 12800000\n",
      "478500 of 12800000\n",
      "479000 of 12800000\n",
      "479500 of 12800000\n",
      "480000 of 12800000\n",
      "480500 of 12800000\n",
      "481000 of 12800000\n",
      "481500 of 12800000\n",
      "482000 of 12800000\n",
      "482500 of 12800000\n",
      "483000 of 12800000\n",
      "483500 of 12800000\n",
      "484000 of 12800000\n",
      "484500 of 12800000\n",
      "485000 of 12800000\n",
      "485500 of 12800000\n",
      "486000 of 12800000\n",
      "486500 of 12800000\n",
      "487000 of 12800000\n",
      "487500 of 12800000\n",
      "488000 of 12800000\n",
      "488500 of 12800000\n",
      "489000 of 12800000\n",
      "489500 of 12800000\n",
      "490000 of 12800000\n",
      "490500 of 12800000\n",
      "491000 of 12800000\n",
      "491500 of 12800000\n",
      "492000 of 12800000\n",
      "492500 of 12800000\n",
      "493000 of 12800000\n",
      "493500 of 12800000\n",
      "494000 of 12800000\n",
      "494500 of 12800000\n",
      "495000 of 12800000\n",
      "495500 of 12800000\n",
      "496000 of 12800000\n",
      "496500 of 12800000\n",
      "497000 of 12800000\n",
      "497500 of 12800000\n",
      "498000 of 12800000\n",
      "498500 of 12800000\n",
      "499000 of 12800000\n",
      "499500 of 12800000\n",
      "500000 of 12800000\n",
      "500500 of 12800000\n",
      "501000 of 12800000\n",
      "501500 of 12800000\n",
      "502000 of 12800000\n",
      "502500 of 12800000\n",
      "503000 of 12800000\n",
      "503500 of 12800000\n",
      "504000 of 12800000\n",
      "504500 of 12800000\n",
      "505000 of 12800000\n",
      "505500 of 12800000\n",
      "506000 of 12800000\n",
      "506500 of 12800000\n",
      "507000 of 12800000\n",
      "507500 of 12800000\n",
      "508000 of 12800000\n",
      "508500 of 12800000\n",
      "509000 of 12800000\n",
      "509500 of 12800000\n",
      "510000 of 12800000\n",
      "510500 of 12800000\n",
      "511000 of 12800000\n",
      "511500 of 12800000\n",
      "512000 of 12800000\n",
      "512500 of 12800000\n",
      "513000 of 12800000\n",
      "513500 of 12800000\n",
      "514000 of 12800000\n",
      "514500 of 12800000\n",
      "515000 of 12800000\n",
      "515500 of 12800000\n",
      "516000 of 12800000\n",
      "516500 of 12800000\n",
      "517000 of 12800000\n",
      "517500 of 12800000\n",
      "518000 of 12800000\n",
      "518500 of 12800000\n",
      "519000 of 12800000\n",
      "519500 of 12800000\n",
      "520000 of 12800000\n",
      "520500 of 12800000\n",
      "521000 of 12800000\n",
      "521500 of 12800000\n",
      "522000 of 12800000\n",
      "522500 of 12800000\n",
      "523000 of 12800000\n",
      "523500 of 12800000\n",
      "524000 of 12800000\n",
      "524500 of 12800000\n",
      "525000 of 12800000\n",
      "525500 of 12800000\n",
      "526000 of 12800000\n",
      "526500 of 12800000\n",
      "527000 of 12800000\n",
      "527500 of 12800000\n",
      "528000 of 12800000\n",
      "528500 of 12800000\n",
      "529000 of 12800000\n",
      "529500 of 12800000\n",
      "530000 of 12800000\n",
      "530500 of 12800000\n",
      "531000 of 12800000\n",
      "531500 of 12800000\n",
      "532000 of 12800000\n",
      "532500 of 12800000\n",
      "533000 of 12800000\n",
      "533500 of 12800000\n",
      "534000 of 12800000\n",
      "534500 of 12800000\n",
      "535000 of 12800000\n",
      "535500 of 12800000\n",
      "536000 of 12800000\n",
      "536500 of 12800000\n",
      "537000 of 12800000\n",
      "537500 of 12800000\n",
      "538000 of 12800000\n",
      "538500 of 12800000\n",
      "539000 of 12800000\n",
      "539500 of 12800000\n",
      "540000 of 12800000\n",
      "540500 of 12800000\n",
      "541000 of 12800000\n",
      "541500 of 12800000\n",
      "542000 of 12800000\n",
      "542500 of 12800000\n",
      "543000 of 12800000\n",
      "543500 of 12800000\n",
      "544000 of 12800000\n",
      "544500 of 12800000\n",
      "545000 of 12800000\n",
      "545500 of 12800000\n",
      "546000 of 12800000\n",
      "546500 of 12800000\n",
      "547000 of 12800000\n",
      "547500 of 12800000\n",
      "548000 of 12800000\n",
      "548500 of 12800000\n",
      "549000 of 12800000\n",
      "549500 of 12800000\n",
      "550000 of 12800000\n",
      "550500 of 12800000\n",
      "551000 of 12800000\n",
      "551500 of 12800000\n",
      "552000 of 12800000\n",
      "552500 of 12800000\n",
      "553000 of 12800000\n",
      "553500 of 12800000\n",
      "554000 of 12800000\n",
      "554500 of 12800000\n",
      "555000 of 12800000\n",
      "555500 of 12800000\n",
      "556000 of 12800000\n",
      "556500 of 12800000\n",
      "557000 of 12800000\n",
      "557500 of 12800000\n",
      "558000 of 12800000\n",
      "558500 of 12800000\n",
      "559000 of 12800000\n",
      "559500 of 12800000\n",
      "560000 of 12800000\n",
      "560500 of 12800000\n",
      "561000 of 12800000\n",
      "561500 of 12800000\n",
      "562000 of 12800000\n",
      "562500 of 12800000\n",
      "563000 of 12800000\n",
      "563500 of 12800000\n",
      "564000 of 12800000\n",
      "564500 of 12800000\n",
      "565000 of 12800000\n",
      "565500 of 12800000\n",
      "566000 of 12800000\n",
      "566500 of 12800000\n",
      "567000 of 12800000\n",
      "567500 of 12800000\n",
      "568000 of 12800000\n",
      "568500 of 12800000\n",
      "569000 of 12800000\n",
      "569500 of 12800000\n",
      "570000 of 12800000\n",
      "570500 of 12800000\n",
      "571000 of 12800000\n",
      "571500 of 12800000\n",
      "572000 of 12800000\n",
      "572500 of 12800000\n",
      "573000 of 12800000\n",
      "573500 of 12800000\n",
      "574000 of 12800000\n",
      "574500 of 12800000\n",
      "575000 of 12800000\n",
      "575500 of 12800000\n",
      "576000 of 12800000\n",
      "576500 of 12800000\n",
      "577000 of 12800000\n",
      "577500 of 12800000\n",
      "578000 of 12800000\n",
      "578500 of 12800000\n",
      "579000 of 12800000\n",
      "579500 of 12800000\n",
      "580000 of 12800000\n",
      "580500 of 12800000\n",
      "581000 of 12800000\n",
      "581500 of 12800000\n",
      "582000 of 12800000\n",
      "582500 of 12800000\n",
      "583000 of 12800000\n",
      "583500 of 12800000\n",
      "584000 of 12800000\n",
      "584500 of 12800000\n",
      "585000 of 12800000\n",
      "585500 of 12800000\n",
      "586000 of 12800000\n",
      "586500 of 12800000\n",
      "587000 of 12800000\n",
      "587500 of 12800000\n",
      "588000 of 12800000\n",
      "588500 of 12800000\n",
      "589000 of 12800000\n",
      "589500 of 12800000\n",
      "590000 of 12800000\n",
      "590500 of 12800000\n",
      "591000 of 12800000\n",
      "591500 of 12800000\n",
      "592000 of 12800000\n",
      "592500 of 12800000\n",
      "593000 of 12800000\n",
      "593500 of 12800000\n",
      "594000 of 12800000\n",
      "594500 of 12800000\n",
      "595000 of 12800000\n",
      "595500 of 12800000\n",
      "596000 of 12800000\n",
      "596500 of 12800000\n",
      "597000 of 12800000\n",
      "597500 of 12800000\n",
      "598000 of 12800000\n",
      "598500 of 12800000\n",
      "599000 of 12800000\n",
      "599500 of 12800000\n",
      "600000 of 12800000\n",
      "600500 of 12800000\n",
      "601000 of 12800000\n",
      "601500 of 12800000\n",
      "602000 of 12800000\n",
      "602500 of 12800000\n",
      "603000 of 12800000\n",
      "603500 of 12800000\n",
      "604000 of 12800000\n",
      "604500 of 12800000\n",
      "605000 of 12800000\n",
      "605500 of 12800000\n",
      "606000 of 12800000\n",
      "606500 of 12800000\n",
      "607000 of 12800000\n",
      "607500 of 12800000\n",
      "608000 of 12800000\n",
      "608500 of 12800000\n",
      "609000 of 12800000\n",
      "609500 of 12800000\n",
      "610000 of 12800000\n",
      "610500 of 12800000\n",
      "611000 of 12800000\n",
      "611500 of 12800000\n",
      "612000 of 12800000\n",
      "612500 of 12800000\n",
      "613000 of 12800000\n",
      "613500 of 12800000\n",
      "614000 of 12800000\n",
      "614500 of 12800000\n",
      "615000 of 12800000\n",
      "615500 of 12800000\n",
      "616000 of 12800000\n",
      "616500 of 12800000\n",
      "617000 of 12800000\n",
      "617500 of 12800000\n",
      "618000 of 12800000\n",
      "618500 of 12800000\n",
      "619000 of 12800000\n",
      "619500 of 12800000\n",
      "620000 of 12800000\n",
      "620500 of 12800000\n",
      "621000 of 12800000\n",
      "621500 of 12800000\n",
      "622000 of 12800000\n",
      "622500 of 12800000\n",
      "623000 of 12800000\n",
      "623500 of 12800000\n",
      "624000 of 12800000\n",
      "624500 of 12800000\n",
      "625000 of 12800000\n",
      "625500 of 12800000\n",
      "626000 of 12800000\n",
      "626500 of 12800000\n",
      "627000 of 12800000\n",
      "627500 of 12800000\n",
      "628000 of 12800000\n",
      "628500 of 12800000\n",
      "629000 of 12800000\n",
      "629500 of 12800000\n",
      "630000 of 12800000\n",
      "630500 of 12800000\n",
      "631000 of 12800000\n",
      "631500 of 12800000\n",
      "632000 of 12800000\n",
      "632500 of 12800000\n",
      "633000 of 12800000\n",
      "633500 of 12800000\n",
      "634000 of 12800000\n",
      "634500 of 12800000\n",
      "635000 of 12800000\n",
      "635500 of 12800000\n",
      "636000 of 12800000\n",
      "636500 of 12800000\n",
      "637000 of 12800000\n",
      "637500 of 12800000\n",
      "638000 of 12800000\n",
      "638500 of 12800000\n",
      "639000 of 12800000\n",
      "639500 of 12800000\n",
      "640000 of 12800000\n",
      "640500 of 12800000\n",
      "641000 of 12800000\n",
      "641500 of 12800000\n",
      "642000 of 12800000\n",
      "642500 of 12800000\n",
      "643000 of 12800000\n",
      "643500 of 12800000\n",
      "644000 of 12800000\n",
      "644500 of 12800000\n",
      "645000 of 12800000\n",
      "645500 of 12800000\n",
      "646000 of 12800000\n",
      "646500 of 12800000\n",
      "647000 of 12800000\n",
      "647500 of 12800000\n",
      "648000 of 12800000\n",
      "648500 of 12800000\n",
      "649000 of 12800000\n",
      "649500 of 12800000\n",
      "650000 of 12800000\n",
      "650500 of 12800000\n",
      "651000 of 12800000\n",
      "651500 of 12800000\n",
      "652000 of 12800000\n",
      "652500 of 12800000\n",
      "653000 of 12800000\n",
      "653500 of 12800000\n",
      "654000 of 12800000\n",
      "654500 of 12800000\n",
      "655000 of 12800000\n",
      "655500 of 12800000\n",
      "656000 of 12800000\n",
      "656500 of 12800000\n",
      "657000 of 12800000\n",
      "657500 of 12800000\n",
      "658000 of 12800000\n",
      "658500 of 12800000\n",
      "659000 of 12800000\n",
      "659500 of 12800000\n",
      "660000 of 12800000\n",
      "660500 of 12800000\n",
      "661000 of 12800000\n",
      "661500 of 12800000\n",
      "662000 of 12800000\n",
      "662500 of 12800000\n",
      "663000 of 12800000\n",
      "663500 of 12800000\n",
      "664000 of 12800000\n",
      "664500 of 12800000\n",
      "665000 of 12800000\n",
      "665500 of 12800000\n",
      "666000 of 12800000\n",
      "666500 of 12800000\n",
      "667000 of 12800000\n",
      "667500 of 12800000\n",
      "668000 of 12800000\n",
      "668500 of 12800000\n",
      "669000 of 12800000\n",
      "669500 of 12800000\n",
      "670000 of 12800000\n",
      "670500 of 12800000\n",
      "671000 of 12800000\n",
      "671500 of 12800000\n",
      "672000 of 12800000\n",
      "672500 of 12800000\n",
      "673000 of 12800000\n",
      "673500 of 12800000\n",
      "674000 of 12800000\n",
      "674500 of 12800000\n",
      "675000 of 12800000\n",
      "675500 of 12800000\n",
      "676000 of 12800000\n",
      "676500 of 12800000\n",
      "677000 of 12800000\n",
      "677500 of 12800000\n",
      "678000 of 12800000\n",
      "678500 of 12800000\n",
      "679000 of 12800000\n",
      "679500 of 12800000\n",
      "680000 of 12800000\n",
      "680500 of 12800000\n",
      "681000 of 12800000\n",
      "681500 of 12800000\n",
      "682000 of 12800000\n",
      "682500 of 12800000\n",
      "683000 of 12800000\n",
      "683500 of 12800000\n",
      "684000 of 12800000\n",
      "684500 of 12800000\n",
      "685000 of 12800000\n",
      "685500 of 12800000\n",
      "686000 of 12800000\n",
      "686500 of 12800000\n",
      "687000 of 12800000\n",
      "687500 of 12800000\n",
      "688000 of 12800000\n",
      "688500 of 12800000\n",
      "689000 of 12800000\n",
      "689500 of 12800000\n",
      "690000 of 12800000\n",
      "690500 of 12800000\n",
      "691000 of 12800000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_2116\\2013430074.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"binomial_training.csv\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"a\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0mpdx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdfxs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mbase\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mbase\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0msz\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0mX_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mpdx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m     \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrun_scenarios\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mr\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[0mS\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mae\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"{S},{K},{T},{r},{v},{cp},{ae},{p}\\n\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_2116\\3635530951.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(X_train)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mscen\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0mS\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mae\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m         value = np.round(option_price_binomial(volatilities=v,\n\u001b[0m\u001b[0;32m      7\u001b[0m                                                \u001b[0mstrikes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mK\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m                                                \u001b[0mexpiries\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m                                                \u001b[0mspots\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mS\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_2116\\3849312526.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(volatilities, strikes, expiries, spots, discount_rates, dividend_rates, is_call_options, is_american, num_steps, dtype, name)\u001b[0m\n\u001b[0;32m    205\u001b[0m         \u001b[0mone_step_back\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mvalues_grid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlog_spot_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    206\u001b[0m         \u001b[0mmaximum_iterations\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_steps\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m         shape_invariants=(tf.TensorShape(batch_shape + [None]),\n\u001b[0;32m    208\u001b[0m                           tf.TensorShape(batch_shape + [None])))\n\u001b[1;32m--> 209\u001b[1;33m     return tf.where(\n\u001b[0m\u001b[0;32m    210\u001b[0m         \u001b[0mexpiries\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    211\u001b[0m         \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    212\u001b[0m         tf.where(is_call_options,\n",
      "\u001b[1;32md:\\anaconda\\anaconda3\\envs\\tfgpu\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    625\u001b[0m                   \u001b[1;34m'will be removed %s.\\nInstructions for updating:\\n%s'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    626\u001b[0m                   \u001b[0m_call_location\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecorator_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_qualified_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    627\u001b[0m                   \u001b[0mfunc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__module__\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg_value\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'in a future version'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    628\u001b[0m                   if date is None else ('after %s' % date), instructions)\n\u001b[1;32m--> 629\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32md:\\anaconda\\anaconda3\\envs\\tfgpu\\lib\\site-packages\\tensorflow\\python\\ops\\control_flow_ops.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(cond, body, loop_vars, shape_invariants, parallel_iterations, back_prop, swap_memory, maximum_iterations, name)\u001b[0m\n\u001b[0;32m   2509\u001b[0m       \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2510\u001b[0m   \u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2511\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2512\u001b[0m   \"\"\"\n\u001b[1;32m-> 2513\u001b[1;33m   return while_loop(\n\u001b[0m\u001b[0;32m   2514\u001b[0m       \u001b[0mcond\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcond\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2515\u001b[0m       \u001b[0mbody\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2516\u001b[0m       \u001b[0mloop_vars\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mloop_vars\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anaconda\\anaconda3\\envs\\tfgpu\\lib\\site-packages\\tensorflow\\python\\ops\\control_flow_ops.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(cond, body, loop_vars, shape_invariants, parallel_iterations, back_prop, swap_memory, name, maximum_iterations, return_same_structure)\u001b[0m\n\u001b[0;32m   2793\u001b[0m                                     return_same_structure)\n\u001b[0;32m   2794\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mmaximum_iterations\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2795\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2796\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2797\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32md:\\anaconda\\anaconda3\\envs\\tfgpu\\lib\\site-packages\\tensorflow\\python\\ops\\control_flow_ops.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(i, lv)\u001b[0m\n\u001b[1;32m-> 2753\u001b[1;33m         \u001b[0mbody\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlv\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morig_body\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mlv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_2116\\3849312526.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(current_values, current_log_spot_grid)\u001b[0m\n\u001b[0;32m    191\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mone_step_back\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcurrent_values\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcurrent_log_spot_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    192\u001b[0m       next_values = (current_values[..., 1:] * p_dn\n\u001b[0;32m    193\u001b[0m                      + current_values[..., :-1] * p_up)\n\u001b[1;32m--> 194\u001b[1;33m       \u001b[0mnext_log_spot_grid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcurrent_log_spot_grid\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m...\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mln_up\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    195\u001b[0m       \u001b[0mnext_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue_mod_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnext_values\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnext_log_spot_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    196\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mdiscount_factors\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mnext_values\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnext_log_spot_grid\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anaconda\\anaconda3\\envs\\tfgpu\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    153\u001b[0m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    154\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 155\u001b[1;33m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32md:\\anaconda\\anaconda3\\envs\\tfgpu\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(x, y)\u001b[0m\n\u001b[0;32m   1421\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1422\u001b[0m           \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1423\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1424\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1425\u001b[1;33m           \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32md:\\anaconda\\anaconda3\\envs\\tfgpu\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    153\u001b[0m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    154\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 155\u001b[1;33m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32md:\\anaconda\\anaconda3\\envs\\tfgpu\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1180\u001b[0m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop_dispatch_handler\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1181\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mOpDispatcher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNOT_SUPPORTED\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1182\u001b[0m           \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1183\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1184\u001b[1;33m           \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32md:\\anaconda\\anaconda3\\envs\\tfgpu\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(x, y, name)\u001b[0m\n\u001b[0;32m    544\u001b[0m \u001b[1;33m@\u001b[0m\u001b[0mtf_export\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"math.subtract\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"subtract\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    545\u001b[0m \u001b[1;33m@\u001b[0m\u001b[0mdispatch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mregister_binary_elementwise_api\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    546\u001b[0m \u001b[1;33m@\u001b[0m\u001b[0mdispatch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_dispatch_support\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0msubtract\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 548\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msub\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32md:\\anaconda\\anaconda3\\envs\\tfgpu\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(x, y, name)\u001b[0m\n\u001b[0;32m  11163\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m  11164\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m  11165\u001b[0m       \u001b[0m_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m  11166\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m> 11167\u001b[1;33m       \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m  11168\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m  11169\u001b[0m       return sub_eager_fallback(\n\u001b[0;32m  11170\u001b[0m           x, y, name=name, ctx=_ctx)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Iterate over the pre-shuffled pandas X_train data in blocks, writing results out as we\n",
    "# go. There are millions of training examples, so we want to make sure results are saved\n",
    "# down. So, fo each block we flush, close and re-open the file in append mode.\n",
    "base = 691000\n",
    "sz = 500\n",
    "all = len(dfxs)\n",
    "\n",
    "while base < all:\n",
    "    # Open in append.\n",
    "    f = open(\"binomial_training.csv\", \"a\")\n",
    "\n",
    "    pdx = dfxs.iloc[base:base+sz]\n",
    "    X_train = (pdx).to_numpy()\n",
    "    results = run_scenarios(X_train)\n",
    "    for r in results:\n",
    "        S, K, T, r, v, cp, ae, p = r\n",
    "        f.write(f\"{S},{K},{T},{r},{v},{cp},{ae},{p}\\n\")\n",
    "    f.flush()\n",
    "    f.close()\n",
    "    base = base + sz\n",
    "    print(f\"{base} of {all}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
